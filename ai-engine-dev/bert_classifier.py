"""
TtalKkac BERT ë¶„ë¥˜ ëª¨ë¸
WhisperX Triplet ë°ì´í„°ë¥¼ ì¤‘ìš”ë„ë³„ë¡œ ë¶„ë¥˜í•˜ëŠ” BERT ê¸°ë°˜ í•„í„°ë§ ì‹œìŠ¤í…œ
"""

import os
import torch
import numpy as np
from typing import List, Dict, Any, Optional
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import logging

logger = logging.getLogger(__name__)

class TtalkkacBERTClassifier:
    """
    íšŒì˜ ë°œí™” ì¤‘ìš”ë„ ë¶„ë¥˜ë¥¼ ìœ„í•œ BERT ëª¨ë¸
    - Label 0: ì¤‘ìš”í•œ ì—…ë¬´ ê´€ë ¨ ë°œí™” (ìœ ì§€)
    - Label 1: ì¡ë‹´, ì¸ì‚¬ë§ ë“± ë¶ˆí•„ìš”í•œ ë°œí™” (ì œê±°)
    """
    
    def __init__(self, model_path: Optional[str] = None):
        self.model_path = model_path or "klue/bert-base"
        self.tokenizer = None
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        logger.info(f"ğŸ§  BERT ë¶„ë¥˜ê¸° ì´ˆê¸°í™” - Device: {self.device}")
    
    def load_model(self):
        """BERT ëª¨ë¸ ë¡œë”©"""
        try:
            logger.info(f"ğŸ“¦ BERT ëª¨ë¸ ë¡œë”©: {self.model_path}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            
            # ëª¨ë¸ ë¡œë“œ (íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì´ ìˆë‹¤ë©´ í•´ë‹¹ ê²½ë¡œ ì‚¬ìš©)
            local_model_path = "../Bertëª¨ë¸/Ttalkkac_model_v2"
            if os.path.exists(local_model_path):
                logger.info("ğŸ¯ ë¡œì»¬ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš©")
                from transformers import AutoConfig
                
                # config ë¡œë“œ (num_labels=2 í™•ì¸)
                config = AutoConfig.from_pretrained(local_model_path, num_labels=2)
                
                # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
                self.model = AutoModelForSequenceClassification.from_config(config)
                
                # .pt íŒŒì¼ ë¡œë“œ (ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•  ì˜ˆì •)
                pt_file_path = os.path.join(local_model_path, "Ttalkkac_model_v2.pt")
                if os.path.exists(pt_file_path):
                    state_dict = torch.load(pt_file_path, map_location=self.device)
                    self.model.load_state_dict(state_dict)
                    logger.info("âœ… íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ .pt íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ BERT ëª¨ë¸ ì‚¬ìš©")
                    self.model = AutoModelForSequenceClassification.from_pretrained(
                        self.model_path, num_labels=2
                    )
            else:
                # ê¸°ë³¸ BERT ëª¨ë¸ ì‚¬ìš©
                logger.info("ğŸ“– ê¸°ë³¸ BERT ëª¨ë¸ ì‚¬ìš©")
                self.model = AutoModelForSequenceClassification.from_pretrained(
                    self.model_path, num_labels=2
                )
            
            # GPUë¡œ ì´ë™
            self.model.to(self.device)
            self.model.eval()
            
            logger.info("âœ… BERT ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ BERT ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise e
    
    def classify_triplet(self, triplet: Dict[str, Any]) -> int:
        """ë‹¨ì¼ Triplet ë¶„ë¥˜"""
        if not self.model or not self.tokenizer:
            self.load_model()
        
        try:
            # Triplet í…ìŠ¤íŠ¸ ê²°í•© (ë§¥ë½ í¬í•¨)
            prev_text = triplet.get("prev", "")
            target_text = triplet.get("target", "")
            next_text = triplet.get("next", "")
            
            # [TGT] íƒœê·¸ ì œê±° í›„ ê²°í•©
            target_clean = target_text.replace("[TGT]", "").replace("[/TGT]", "").strip()
            combined_text = f"{prev_text} {target_clean} {next_text}".strip()
            
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                combined_text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512
            )
            
            # GPUë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(**inputs)
                prediction = torch.argmax(outputs.logits, dim=-1)
                confidence = torch.softmax(outputs.logits, dim=-1)
            
            label = prediction.item()
            conf_score = confidence[0][label].item()
            
            return {
                "label": label,  # 0: ì¤‘ìš”, 1: ë…¸ì´ì¦ˆ
                "confidence": conf_score,
                "text_length": len(combined_text)
            }
            
        except Exception as e:
            logger.error(f"âŒ Triplet ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’: ì¤‘ìš”í•œ ë°œí™”ë¡œ ë¶„ë¥˜ (ì•ˆì „ì¥ì¹˜)
            return {"label": 0, "confidence": 0.5, "text_length": 0}
    
    def classify_triplets_batch(self, triplets: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Triplet ë°°ì¹˜ ë¶„ë¥˜"""
        logger.info(f"ğŸ” BERT ë¶„ë¥˜ ì‹œì‘: {len(triplets)}ê°œ Triplet")
        
        classified_triplets = []
        important_count = 0
        noise_count = 0
        
        for i, triplet in enumerate(triplets):
            try:
                # ë¶„ë¥˜ ìˆ˜í–‰
                classification = self.classify_triplet(triplet)
                
                # ê²°ê³¼ ì¶”ê°€
                triplet_with_label = triplet.copy()
                triplet_with_label["label"] = classification["label"]
                triplet_with_label["confidence"] = classification["confidence"]
                
                classified_triplets.append(triplet_with_label)
                
                # í†µê³„ ìˆ˜ì§‘
                if classification["label"] == 0:
                    important_count += 1
                else:
                    noise_count += 1
                    
                # ì§„í–‰ë¥  ë¡œê·¸
                if (i + 1) % 50 == 0 or (i + 1) == len(triplets):
                    logger.info(f"ğŸ“Š ë¶„ë¥˜ ì§„í–‰ë¥ : {i+1}/{len(triplets)} ({((i+1)/len(triplets)*100):.1f}%)")
                    
            except Exception as e:
                logger.error(f"âŒ Triplet {i} ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¤‘ìš”í•œ ë°œí™”ë¡œ ë¶„ë¥˜
                triplet["label"] = 0
                triplet["confidence"] = 0.5
                classified_triplets.append(triplet)
                important_count += 1
        
        # ë¶„ë¥˜ ê²°ê³¼ í†µê³„
        total = len(triplets)
        noise_ratio = (noise_count / total) * 100 if total > 0 else 0
        
        logger.info(f"âœ… BERT ë¶„ë¥˜ ì™„ë£Œ")
        logger.info(f"ğŸ“ˆ ë¶„ë¥˜ í†µê³„:")
        logger.info(f"   - ì „ì²´: {total}ê°œ")
        logger.info(f"   - ì¤‘ìš” ë°œí™”: {important_count}ê°œ ({100-noise_ratio:.1f}%)")
        logger.info(f"   - ë…¸ì´ì¦ˆ ë°œí™”: {noise_count}ê°œ ({noise_ratio:.1f}%)")
        
        return classified_triplets
    
    def get_classification_stats(self, classified_triplets: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë¶„ë¥˜ í†µê³„ ìƒì„±"""
        total = len(classified_triplets)
        important = sum(1 for t in classified_triplets if t.get("label") == 0)
        noise = total - important
        
        return {
            "total_triplets": total,
            "important_triplets": important,
            "noise_triplets": noise,
            "noise_reduction_ratio": (noise / total) if total > 0 else 0,
            "avg_confidence": np.mean([t.get("confidence", 0.5) for t in classified_triplets]),
            "method": "BERT-based classification"
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
bert_classifier = None

def get_bert_classifier() -> TtalkkacBERTClassifier:
    """BERT ë¶„ë¥˜ê¸° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global bert_classifier
    
    if bert_classifier is None:
        bert_classifier = TtalkkacBERTClassifier()
        bert_classifier.load_model()
    
    return bert_classifier