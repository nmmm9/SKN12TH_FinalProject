import json
import os
from typing import List, Dict, Any
from openai import OpenAI
from datetime import datetime
from pathlib import Path
from prd_generation_prompts import generate_notion_project_prompt, generate_task_master_prd_prompt

class TtalkkakGoldStandardGenerator:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def get_meeting_files(self, base_dir: str = "batch_triplet_results") -> List[str]:
        """05_final_result.json íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë°˜í™˜"""
        target_files = []
        
        if os.path.exists(base_dir):
            for root, dirs, files in os.walk(base_dir):
                for file in files:
                    if file == "05_final_result.json":
                        target_files.append(os.path.join(root, file))
        
        return target_files
    
    def load_meeting_data(self, file_path: str) -> Dict[str, Any]:
        """íšŒì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # íšŒì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            meeting_text = ""
            for item in data:
                timestamp = item.get('timestamp', 'Unknown')
                speaker = item.get('speaker', 'Unknown')
                text = item.get('text', '')
                meeting_text += f"[{timestamp}] {speaker}: {text}\n"
            
            return {
                "transcript": meeting_text.strip(),
                "metadata": {
                    "source_file": file_path,
                    "utterance_count": len(data),
                    "transcript_length": len(meeting_text),
                    "speakers": list(set(item.get('speaker', 'Unknown') for item in data))
                }
            }
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}")
            return None
    
    def generate_initial_notion_response(self, meeting_transcript: str) -> Dict[str, Any]:
        """ì´ˆê¸° ë…¸ì…˜ í”„ë¡œì íŠ¸ ìƒì„±"""
        try:
            prompt = generate_notion_project_prompt(meeting_transcript)
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ì„ ë¶„ì„í•´ì„œ êµ¬ì¡°í™”ëœ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def evaluate_notion_response(self, meeting_transcript: str, initial_response: Any) -> Dict[str, Any]:
        """ë…¸ì…˜ ì‘ë‹µ í‰ê°€"""
        try:
            evaluation_prompt = f"""
ë‹¤ìŒ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”.

**íšŒì˜ë¡:**
{meeting_transcript}

**í˜„ì¬ ê¸°íšì•ˆ:**
{json.dumps(initial_response, ensure_ascii=False, indent=2)}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
{{
    "1_to_5_ì ìˆ˜": {{
        "íšŒì˜ë‚´ìš©_ë°˜ì˜ë„": ì ìˆ˜,
        "êµ¬ì¡°í™”_í’ˆì§ˆ": ì ìˆ˜,
        "ì‹¤í–‰ê°€ëŠ¥ì„±": ì ìˆ˜,
        "ì™„ì„±ë„": ì ìˆ˜
    }},
    "overall_score": ì „ì²´_í‰ê· ì ìˆ˜,
    "strengths": ["ì¥ì 1", "ì¥ì 2"],
    "critical_issues": ["ì‹¬ê°í•œë¬¸ì œ1", "ì‹¬ê°í•œë¬¸ì œ2"],
    "missing_information": ["ëˆ„ë½ì •ë³´1", "ëˆ„ë½ì •ë³´2"],
    "improvement_suggestions": ["ê°œì„ ì‚¬í•­1", "ê°œì„ ì‚¬í•­2"]
}}

í‰ê°€ ê¸°ì¤€: ê° 1-5ì  ì²™ë„ (5ì  ë§Œì )
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ ê¸°ë°˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": evaluation_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": {"evaluation": result, "overall_score": 3.0}}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def refine_notion_response(self, meeting_transcript: str, initial_response: Any, evaluation: Dict) -> Dict[str, Any]:
        """ë…¸ì…˜ ì‘ë‹µ ê°œì„ """
        try:
            refinement_prompt = f"""
íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ê°œì„ í•´ì£¼ì„¸ìš”.

**íšŒì˜ë¡:**
{meeting_transcript}

**í˜„ì¬ ê¸°íšì•ˆ:**
{json.dumps(initial_response, ensure_ascii=False, indent=2)}

**í‰ê°€ ê²°ê³¼:**
- ì „ì²´ ì ìˆ˜: {evaluation.get('overall_score', 0)}/5
- ê°•ì : {evaluation.get('strengths', [])}
- ì‹¬ê°í•œ ë¬¸ì œ: {evaluation.get('critical_issues', [])}
- ëˆ„ë½ ì •ë³´: {evaluation.get('missing_information', [])}
- ê°œì„  ì œì•ˆ: {evaluation.get('improvement_suggestions', [])}

ìœ„ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°íšì•ˆì„ ê°œì„ í•´ì„œ ì™„ë²½í•œ ë…¸ì…˜ í”„ë¡œì íŠ¸ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ì„ ë¶„ì„í•´ì„œ ì™„ë²½í•œ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": refinement_prompt}
                ],
                temperature=0.5,
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def generate_prd_from_notion(self, refined_notion: Any) -> Dict[str, Any]:
        """ê°œì„ ëœ ë…¸ì…˜ì—ì„œ PRD ìƒì„±"""
        try:
            prd_prompt = generate_task_master_prd_prompt(refined_notion)
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¸ì…˜ í”„ë¡œì íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Task Master PRDë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prd_prompt}
                ],
                temperature=0.6,
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def final_quality_check(self, notion_result: Any, prd_result: Any) -> Dict[str, Any]:
        """ìµœì¢… í’ˆì§ˆ ê²€ì‚¬"""
        try:
            quality_prompt = f"""
ìƒì„±ëœ ë…¸ì…˜ í”„ë¡œì íŠ¸ì™€ PRDì˜ ìµœì¢… í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”.

**ë…¸ì…˜ í”„ë¡œì íŠ¸:**
{json.dumps(notion_result, ensure_ascii=False, indent=2)}

**PRD ê²°ê³¼:**
{json.dumps(prd_result, ensure_ascii=False, indent=2)}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìµœì¢… í‰ê°€í•´ì£¼ì„¸ìš”:
{{
    "final_score": ì „ì²´_í‰ê· ì ìˆ˜,
    "is_production_ready": true/false,
    "quality_breakdown": {{
        "notion_quality": ì ìˆ˜,
        "prd_quality": ì ìˆ˜,
        "consistency": ì ìˆ˜,
        "completeness": ì ìˆ˜
    }},
    "final_recommendations": ["ìµœì¢…ê¶Œì¥ì‚¬í•­1", "ìµœì¢…ê¶Œì¥ì‚¬í•­2"]
}}

í‰ê°€ ê¸°ì¤€: ê° 1-5ì  ì²™ë„ (5ì  ë§Œì )
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì‚°ì¶œë¬¼ì˜ ìµœì¢… í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": quality_prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": {"final_score": 3.0, "is_production_ready": True}}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def generate_gold_standard_sample(self, meeting_transcript: str, metadata: Dict) -> Dict[str, Any]:
        """í•˜ë‚˜ì˜ íšŒì˜ë¡ì— ëŒ€í•œ ì™„ì „í•œ ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ìƒì„±"""
        
        # Stage 1: ì´ˆê¸° ë…¸ì…˜ ì‘ë‹µ ìƒì„±
        print("      ğŸ¯ Stage 1: ì´ˆê¸° ë…¸ì…˜ í”„ë¡œì íŠ¸ ìƒì„±...")
        initial_notion = self.generate_initial_notion_response(meeting_transcript)
        if not initial_notion["success"]:
            return {"success": False, "error": f"Stage 1 ì‹¤íŒ¨: {initial_notion['error']}"}
        
        # Stage 2: ì´ˆê¸° ì‘ë‹µ í‰ê°€
        print("      ğŸ“Š Stage 2: ì´ˆê¸° ì‘ë‹µ í’ˆì§ˆ í‰ê°€...")
        evaluation = self.evaluate_notion_response(meeting_transcript, initial_notion["result"])
        if not evaluation["success"]:
            return {"success": False, "error": f"Stage 2 ì‹¤íŒ¨: {evaluation['error']}"}
        
        iterations_used = 1
        final_notion = initial_notion["result"]
        
        # Stage 3: í•„ìš”ì‹œ ê°œì„  (í’ˆì§ˆì´ 4.3ì  ë¯¸ë§Œì¸ ê²½ìš°ë§Œ)
        if evaluation["result"].get("overall_score", 0) < 4.3:
            print("      âš¡ Stage 3: ì‘ë‹µ ê°œì„  ì¤‘...")
            refined_notion = self.refine_notion_response(
                meeting_transcript, 
                initial_notion["result"], 
                evaluation["result"]
            )
            if not refined_notion["success"]:
                return {"success": False, "error": f"Stage 3 ì‹¤íŒ¨: {refined_notion['error']}"}
            
            final_notion = refined_notion["result"]
            iterations_used = 2
        else:
            print("      âœ… Stage 3: í’ˆì§ˆ ìš°ìˆ˜ë¡œ ê°œì„  ë‹¨ê³„ ìƒëµ")
        
        # Stage 4: PRD ìƒì„±
        print("      ğŸ“‹ Stage 4: PRD ìƒì„±...")
        prd_result = self.generate_prd_from_notion(final_notion)
        if not prd_result["success"]:
            return {"success": False, "error": f"Stage 4 ì‹¤íŒ¨: {prd_result['error']}"}
        
        # Stage 5: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬
        print("      ğŸ” Stage 5: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬...")
        final_quality = self.final_quality_check(final_notion, prd_result["result"])
        if not final_quality["success"]:
            return {"success": False, "error": f"Stage 5 ì‹¤íŒ¨: {final_quality['error']}"}
        
        return {
            "success": True,
            "notion_result": final_notion,
            "prd_result": prd_result["result"],
            "final_quality": final_quality["result"],
            "iterations_used": iterations_used
        }

def split_train_val(file_paths: List[str], train_ratio: float = 0.8) -> tuple:
    """íŒŒì¼ì„ í•™ìŠµ/ê²€ì¦ìš©ìœ¼ë¡œ ë¶„í• """
    import random
    random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
    
    shuffled_paths = file_paths.copy()
    random.shuffle(shuffled_paths)
    
    split_idx = int(len(shuffled_paths) * train_ratio)
    train_files = shuffled_paths[:split_idx]
    val_files = shuffled_paths[split_idx:]
    
    return train_files, val_files

def get_dir_name_from_path(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œì—ì„œ ë””ë ‰í† ë¦¬ ì´ë¦„ ì¶”ì¶œ"""
    return os.path.basename(os.path.dirname(file_path))

def print_processing_summary(processing_stats: Dict):
    """ì²˜ë¦¬ ìš”ì•½ ì¶œë ¥"""
    if processing_stats['processed'] > 0:
        print(f"   ğŸ“ˆ ì²˜ë¦¬ ì™„ë£Œ: {processing_stats['processed']}ê°œ")
        print(f"   âœ… ì„±ê³µ: {processing_stats['success']}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {processing_stats['failed']}ê°œ")
        print(f"   ğŸ“ˆ ì„±ê³µë¥ : {processing_stats['success']/processing_stats['processed']*100:.1f}%")

def process_dataset_batch(generator: TtalkkakGoldStandardGenerator, 
                         data_dirs: List[str], 
                         dataset_type: str,
                         stats: Dict) -> List[Dict]:
    """ë°ì´í„°ì…‹ ë°°ì¹˜ ì²˜ë¦¬"""
    dataset = []
    
    for i, file_path in enumerate(data_dirs):
        dir_name = get_dir_name_from_path(file_path)
        print(f"   ğŸ“ [{i+1}/{len(data_dirs)}] {dir_name} ì²˜ë¦¬ ì¤‘...")
        
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ë°±ì—… íŒŒì¼ ìƒì„±
        backup_file = f"backup_{dataset_type}_{i+1:03d}_{dir_name}.json"
        try:
            meeting_data = generator.load_meeting_data(file_path)
            if not meeting_data:
                stats["failed"] += 1
                print(f"      ğŸ’¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                continue
            
            # ë°±ì—… ì €ì¥
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(meeting_data, f, ensure_ascii=False, indent=2)
            
            meeting_transcript = meeting_data["transcript"]
            metadata = meeting_data["metadata"]
            
            print(f"      ğŸ”„ 5ë‹¨ê³„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
            
            result = generator.generate_gold_standard_sample(meeting_transcript, metadata)
            stats["processed"] += 1
            
            if result["success"]:
                quality_score = result["final_quality"].get("final_score", 0)
                is_production_ready = result["final_quality"].get("is_production_ready", False)
                
                print(f"      ğŸ“Š ìµœì¢… í’ˆì§ˆ: {quality_score}/5, í”„ë¡œë•ì…˜ ì¤€ë¹„: {is_production_ready}")
                
                # í’ˆì§ˆ ê¸°ì¤€ (ê´€ëŒ€í•˜ê²Œ ì„¤ì •)
                if quality_score >= 3.5:  # 3.5ì  ì´ìƒì´ë©´ ìˆ˜ìš© (5ì  ì²™ë„)
                    training_sample = {
                        "id": f"{dataset_type}_{i+1:03d}",
                        "source_dir": dir_name,
                        "notion_output": result["notion_result"],
                        "prd_output": result["prd_result"],
                        "quality_metrics": {
                            "final_score": quality_score,
                            "is_production_ready": is_production_ready,
                            "iterations_used": result["iterations_used"]
                        },
                        "metadata": {
                            **metadata,
                            "dataset_type": dataset_type,
                            "processing_date": datetime.now().isoformat()
                        }
                    }
                    
                    dataset.append(training_sample)
                    stats["success"] += 1
                    print(f"      âœ… ì €ì¥ ì™„ë£Œ (í’ˆì§ˆ: {quality_score}/5)")
                else:
                    stats["failed"] += 1
                    print(f"      âŒ í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ (ì ìˆ˜: {quality_score}/5)")
            else:
                stats["failed"] += 1
                print(f"      ğŸ’¥ ìƒì„± ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            # ë°±ì—… íŒŒì¼ ì •ë¦¬
            if os.path.exists(backup_file):
                os.remove(backup_file)
                
        except Exception as e:
            stats["failed"] += 1
            stats["processed"] += 1
            print(f"      ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            if os.path.exists(backup_file):
                os.remove(backup_file)
    
    return dataset

def save_final_datasets(train_dataset: List[Dict], val_dataset: List[Dict], stats: Dict):
    """ìµœì¢… ë°ì´í„°ì…‹ ë° í†µê³„ ì €ì¥"""
    
    # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í´ë” ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = Path(f"ttalkkac_gold_standard_results_{timestamp}")
    results_dir.mkdir(exist_ok=True)
    
    train_file = results_dir / "ttalkkac_train_gold_standard.json"
    val_file = results_dir / "ttalkkac_val_gold_standard.json"
    
    # í•™ìŠµ ë°ì´í„° ì €ì¥
    with open(train_file, 'w', encoding='utf-8') as f:
        json.dump(train_dataset, f, ensure_ascii=False, indent=2)
    
    # ê²€ì¦ ë°ì´í„° ì €ì¥
    with open(val_file, 'w', encoding='utf-8') as f:
        json.dump(val_dataset, f, ensure_ascii=False, indent=2)
    
    # í†µê³„ ê³„ì‚° ë° ì €ì¥
    if train_dataset:
        train_quality_avg = sum(s["quality_metrics"]["final_score"] for s in train_dataset) / len(train_dataset)
        train_lengths = [s["metadata"]["transcript_length"] for s in train_dataset]
    else:
        train_quality_avg = 0
        train_lengths = []
        
    if val_dataset:
        val_quality_avg = sum(s["quality_metrics"]["final_score"] for s in val_dataset) / len(val_dataset)
        val_lengths = [s["metadata"]["transcript_length"] for s in val_dataset]
    else:
        val_quality_avg = 0
        val_lengths = []
    
    final_stats = {
        **stats,
        "end_time": datetime.now().isoformat(),
        "final_train_count": len(train_dataset),
        "final_val_count": len(val_dataset),
        "train_quality_average": train_quality_avg,
        "val_quality_average": val_quality_avg,
        "train_length_stats": {
            "min": min(train_lengths) if train_lengths else 0,
            "max": max(train_lengths) if train_lengths else 0,
            "avg": sum(train_lengths) / len(train_lengths) if train_lengths else 0
        },
        "val_length_stats": {
            "min": min(val_lengths) if val_lengths else 0,
            "max": max(val_lengths) if val_lengths else 0,
            "avg": sum(val_lengths) / len(val_lengths) if val_lengths else 0
        }
    }
    
    stats_file = results_dir / "ttalkkac_generation_statistics.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(final_stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤ ({results_dir}):")
    print(f"   ğŸ“š ttalkkac_train_gold_standard.json ({len(train_dataset)}ê°œ ìƒ˜í”Œ)")
    print(f"   ğŸ” ttalkkac_val_gold_standard.json ({len(val_dataset)}ê°œ ìƒ˜í”Œ)")
    print(f"   ğŸ“Š ttalkkac_generation_statistics.json")
    print(f"\nğŸ“ˆ í’ˆì§ˆ í†µê³„:")
    print(f"   í•™ìŠµ ë°ì´í„° í‰ê·  í’ˆì§ˆ: {train_quality_avg:.2f}/5")
    print(f"   ê²€ì¦ ë°ì´í„° í‰ê·  í’ˆì§ˆ: {val_quality_avg:.2f}/5")

if __name__ == "__main__":
    # OpenAI API í‚¤ ì„¤ì •
    API_KEY = os.getenv("OPENAI_API_KEY")
    if not API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("Windows: set OPENAI_API_KEY=your_api_key_here")
        print("Linux/Mac: export OPENAI_API_KEY=your_api_key_here")
        exit(1)
    
    print("ğŸš€ TtalKkac ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘!")
    print("=" * 60)
    
    # ì²˜ë¦¬ í†µê³„
    stats = {
        "start_time": datetime.now().isoformat(),
        "processed": 0,
        "success": 0,
        "failed": 0
    }
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = TtalkkakGoldStandardGenerator(api_key=API_KEY)
    
    # íšŒì˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
    meeting_files = generator.get_meeting_files("../batch_triplet_results")
    if not meeting_files:
        print("âŒ batch_triplet_results í´ë”ì—ì„œ 05_final_result.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    print(f"ğŸ“Š ë°œê²¬ëœ íšŒì˜ íŒŒì¼: {len(meeting_files)}ê°œ")
    
    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
    train_dirs, val_dirs = split_train_val(meeting_files, train_ratio=0.8)
    print(f"ğŸ“š í•™ìŠµìš©: {len(train_dirs)}ê°œ")
    print(f"ğŸ” ê²€ì¦ìš©: {len(val_dirs)}ê°œ")
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = TtalkkakGoldStandardGenerator(api_key=API_KEY)
    
    # ê²°ê³¼ ì €ì¥ìš©
    train_dataset = []
    val_dataset = []
    
    print(f"\nğŸ“š í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
    print("=" * 40)
    train_dataset = process_dataset_batch(generator, train_dirs, "train", stats)
    
    print(f"\nğŸ” ê²€ì¦ ë°ì´í„° ìƒì„± ì¤‘...")
    print("=" * 40)
    val_dataset = process_dataset_batch(generator, val_dirs, "val", stats)
    
    # ìµœì¢… ì €ì¥
    print(f"\nğŸ’¾ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì¤‘...")
    save_final_datasets(train_dataset, val_dataset, stats)
    
    print(f"\nâœ… ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ìƒì„± ì™„ë£Œ!")
    print("=" * 60)