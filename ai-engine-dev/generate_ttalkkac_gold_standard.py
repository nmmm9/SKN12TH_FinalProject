import json
import os
from typing import List, Dict, Any
from openai import OpenAI
from datetime import datetime
from pathlib import Path
from prd_generation_prompts import generate_notion_project_prompt, generate_task_master_prd_prompt

class TtalkkakGoldStandardGenerator:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def get_meeting_files(self, base_dir: str = "batch_triplet_results") -> List[str]:
        """05_final_result.json íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë°˜í™˜"""
        target_files = []
        
        if os.path.exists(base_dir):
            for root, dirs, files in os.walk(base_dir):
                for file in files:
                    if file == "05_final_result.json":
                        target_files.append(os.path.join(root, file))
        
        return target_files
    
    def load_meeting_data(self, file_path: str) -> Dict[str, Any]:
        """íšŒì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # íšŒì˜ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            meeting_text = ""
            for item in data:
                timestamp = item.get('timestamp', 'Unknown')
                speaker = item.get('speaker', 'Unknown')
                text = item.get('text', '')
                meeting_text += f"[{timestamp}] {speaker}: {text}\n"
            
            return {
                "transcript": meeting_text.strip(),
                "metadata": {
                    "source_file": file_path,
                    "utterance_count": len(data),
                    "transcript_length": len(meeting_text),
                    "speakers": list(set(item.get('speaker', 'Unknown') for item in data))
                }
            }
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}")
            return None
    
    def generate_initial_notion_response(self, meeting_transcript: str) -> Dict[str, Any]:
        """ì´ˆê¸° ë…¸ì…˜ í”„ë¡œì íŠ¸ ìƒì„±"""
        try:
            prompt = generate_notion_project_prompt(meeting_transcript)
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ì„ ë¶„ì„í•´ì„œ êµ¬ì¡°í™”ëœ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def evaluate_notion_response(self, meeting_transcript: str, initial_response: Any) -> Dict[str, Any]:
        """ë…¸ì…˜ ì‘ë‹µ í‰ê°€"""
        try:
            evaluation_prompt = f"""
ë‹¹ì‹ ì€ íšŒì˜ë¡ ê¸°ë°˜ ë…¸ì…˜ ê¸°íšì•ˆì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ í‰ê°€ìì…ë‹ˆë‹¤.

**ì›ë³¸ íšŒì˜ë¡:**
{meeting_transcript}

**ìƒì„±ëœ ë…¸ì…˜ ê¸°íšì•ˆ:**
{json.dumps(initial_response, ensure_ascii=False, indent=2)}

**í‰ê°€ ê¸°ì¤€ (ê° 1-10ì  ì²™ë„):**

1. **íšŒì˜ ë‚´ìš© ë°˜ì˜ë„ (Meeting Fidelity)**: 
   - íšŒì˜ì—ì„œ ë…¼ì˜ëœ ë‚´ìš©ì´ ì •í™•íˆ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
   - íšŒì˜ì˜ í•µì‹¬ ì£¼ì œì™€ ê²°ì •ì‚¬í•­ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?

2. **í”„ë¡œì íŠ¸ ì •ë³´ ì™„ì„±ë„ (Project Completeness)**: 
   - í”„ë¡œì íŠ¸ëª…, ëª©ì , ë‹´ë‹¹ì ë“± í•„ìˆ˜ ì •ë³´ê°€ ì ì ˆíˆ ì¶”ì¶œë˜ì—ˆëŠ”ê°€?
   - ì‹¤í–‰ ê³„íšê³¼ ê¸°ëŒ€ íš¨ê³¼ê°€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?

3. **ì‹¤ë¬´ í™œìš©ì„± (Practical Usability)**: 
   - ì‹¤ì œ ì—…ë¬´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ê¸°ìˆ ê³¼ ì§€ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
   - êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšì¸ê°€?

4. **ë…¼ë¦¬ì  ì¼ê´€ì„± (Logical Consistency)**: 
   - í”„ë¡œì íŠ¸ ëª©ì ê³¼ ì‹¤í–‰ ê³„íšì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ê°€?
   - ê¸°ëŒ€ íš¨ê³¼ê°€ í”„ë¡œì íŠ¸ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?

5. **í•œêµ­ì–´ í’ˆì§ˆ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì í•©ì„± (Korean Business Quality)**: 
   - ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ í‘œí˜„ì¸ê°€?

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "scores": {{
        "meeting_fidelity": ì ìˆ˜,
        "project_completeness": ì ìˆ˜,
        "practical_usability": ì ìˆ˜,
        "logical_consistency": ì ìˆ˜,
        "korean_business_quality": ì ìˆ˜
    }},
    "overall_score": í‰ê· ì ìˆ˜,
    "strengths": ["êµ¬ì²´ì ì¸ ê°•ì 1", "êµ¬ì²´ì ì¸ ê°•ì 2"],
    "critical_issues": ["ë°˜ë“œì‹œ ìˆ˜ì •í•´ì•¼ í•  ë¬¸ì œ1", "ë°˜ë“œì‹œ ìˆ˜ì •í•´ì•¼ í•  ë¬¸ì œ2"],
    "improvement_suggestions": [
        "êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ1 (ì–´ë–¤ ë¶€ë¶„ì„ ì–´ë–»ê²Œ ìˆ˜ì •í• ì§€)",
        "êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ2",
        "êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ3"
    ],
    "missing_information": ["íšŒì˜ì—ì„œ ì–¸ê¸‰ëì§€ë§Œ ëˆ„ë½ëœ ì •ë³´ë“¤"],
    "needs_refinement": true/false
}}
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ ê¸°ë°˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": evaluation_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            result = response.choices[0].message.content
            print(f"      ğŸ” í‰ê°€ ì‘ë‹µ (ì²˜ìŒ 300ì): {result[:300]}...")
            
            # JSON ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì œê±°
            if result.startswith("```json"):
                result = result[7:]  # ```json ì œê±°
            if result.startswith("```"):
                result = result[3:]   # ``` ì œê±°
            if result.endswith("```"):
                result = result[:-3]  # ëì˜ ``` ì œê±°
            result = result.strip()
            
            try:
                parsed_result = json.loads(result)
                actual_score = parsed_result.get("overall_score", 6.0)
                print(f"      ğŸ“Š íŒŒì‹± ì„±ê³µ! ì‹¤ì œ ì ìˆ˜: {actual_score}")
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError as e:
                print(f"      âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                print(f"      ğŸ” ì •ë¦¬ëœ ì‘ë‹µ: {result[:200]}...")
                return {"success": True, "result": {"evaluation": result, "overall_score": 6.0}}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def refine_notion_response(self, meeting_transcript: str, initial_response: Any, evaluation: Dict) -> Dict[str, Any]:
        """ë…¸ì…˜ ì‘ë‹µ ê°œì„ """
        try:
            refinement_prompt = f"""
íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ê°œì„ í•´ì£¼ì„¸ìš”.

**íšŒì˜ë¡:**
{meeting_transcript}

**í˜„ì¬ ê¸°íšì•ˆ:**
{json.dumps(initial_response, ensure_ascii=False, indent=2)}

**í‰ê°€ ê²°ê³¼:**
- ì „ì²´ ì ìˆ˜: {evaluation.get('overall_score', 0)}/10
- ê°•ì : {evaluation.get('strengths', [])}
- ì‹¬ê°í•œ ë¬¸ì œ: {evaluation.get('critical_issues', [])}
- ëˆ„ë½ ì •ë³´: {evaluation.get('missing_information', [])}
- ê°œì„  ì œì•ˆ: {evaluation.get('improvement_suggestions', [])}

ìœ„ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°íšì•ˆì„ ê°œì„ í•´ì£¼ì„¸ìš”.

**í•„ìˆ˜ ê°œì„  ì‚¬í•­:**
1. ì‹¬ê°í•œ ë¬¸ì œë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í•´ê²°í•˜ì„¸ìš”
2. ëˆ„ë½ëœ ì •ë³´ë¥¼ íšŒì˜ ë‚´ìš©ì—ì„œ ì°¾ì•„ ë³´ì™„í•˜ì„¸ìš”
3. ê°œì„  ì œì•ˆì‚¬í•­ì„ ë°˜ì˜í•´ì„œ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
4. í”„ë¡œì íŠ¸ëª…, ëª©ì , ì‹¤í–‰ê³„íšì„ ë” ëª…í™•í•˜ê²Œ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”
5. íšŒì˜ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ë‚´ìš©ë“¤ì„ ë” ë§ì´ í¬í•¨ì‹œí‚¤ì„¸ìš”

**ëª©í‘œ**: ì´ì „ ë²„ì „ë³´ë‹¤ ë°˜ë“œì‹œ ë” ë‚˜ì€ ê¸°íšì•ˆì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ **ì™„ì „íˆ ìƒˆë¡œìš´ ê°œì„ ëœ ê¸°íšì•ˆ**ì„ ì‘ë‹µí•˜ì„¸ìš”:
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ì„ ë¶„ì„í•´ì„œ ì™„ë²½í•œ ë…¸ì…˜ í”„ë¡œì íŠ¸ ê¸°íšì•ˆì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": refinement_prompt}
                ],
                temperature=0.3,  # ì‚¬ì‹¤ ê¸°ë°˜ íšŒì˜ë¡ ìƒì„±ì„ ìœ„í•´ ë‚®ê²Œ ìœ ì§€
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def generate_prd_from_notion(self, refined_notion: Any) -> Dict[str, Any]:
        """ê°œì„ ëœ ë…¸ì…˜ì—ì„œ PRD ìƒì„±"""
        try:
            # refined_notionì´ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(refined_notion, str):
                print(f"      âš ï¸ ë…¸ì…˜ ê²°ê³¼ê°€ ë¬¸ìì—´ì…ë‹ˆë‹¤. JSON íŒŒì‹± ì‹œë„...")
                try:
                    refined_notion = json.loads(refined_notion)
                except:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ êµ¬ì¡° ì‚¬ìš©
                    refined_notion = {
                        "project_name": "íŒŒì‹±ëœ í”„ë¡œì íŠ¸",
                        "project_purpose": "íšŒì˜ ë‚´ìš© ê¸°ë°˜ í”„ë¡œì íŠ¸",
                        "core_idea": "í•µì‹¬ ì•„ì´ë””ì–´",
                        "execution_plan": "ì‹¤í–‰ ê³„íš",
                        "core_objectives": ["ëª©í‘œ1", "ëª©í‘œ2"],
                        "expected_effects": ["íš¨ê³¼1", "íš¨ê³¼2"]
                    }
            
            prd_prompt = generate_task_master_prd_prompt(refined_notion)
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¸ì…˜ í”„ë¡œì íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Task Master PRDë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prd_prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def final_quality_check(self, notion_result: Any, prd_result: Any) -> Dict[str, Any]:
        """ìµœì¢… í’ˆì§ˆ ê²€ì‚¬"""
        try:
            quality_prompt = f"""
ìƒì„±ëœ ë…¸ì…˜ í”„ë¡œì íŠ¸ì™€ PRDì˜ ìµœì¢… í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”.

**ë…¸ì…˜ í”„ë¡œì íŠ¸:**
{json.dumps(notion_result, ensure_ascii=False, indent=2)}

**PRD ê²°ê³¼:**
{json.dumps(prd_result, ensure_ascii=False, indent=2)}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìµœì¢… í‰ê°€í•´ì£¼ì„¸ìš”:
{{
    "final_score": ì „ì²´_í‰ê· ì ìˆ˜,
    "is_production_ready": true/false,
    "quality_breakdown": {{
        "notion_quality": ì ìˆ˜,
        "prd_quality": ì ìˆ˜,
        "consistency": ì ìˆ˜,
        "completeness": ì ìˆ˜
    }},
    "final_recommendations": ["ìµœì¢…ê¶Œì¥ì‚¬í•­1", "ìµœì¢…ê¶Œì¥ì‚¬í•­2"]
}}

í‰ê°€ ê¸°ì¤€: ê° 1-10ì  ì²™ë„ (10ì  ë§Œì )
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì‚°ì¶œë¬¼ì˜ ìµœì¢… í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": quality_prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            result = response.choices[0].message.content
            try:
                parsed_result = json.loads(result)
                return {"success": True, "result": parsed_result}
            except json.JSONDecodeError:
                return {"success": True, "result": {"final_score": 6.0, "is_production_ready": True}}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def generate_gold_standard_sample(self, meeting_transcript: str, metadata: Dict) -> Dict[str, Any]:
        """í•˜ë‚˜ì˜ íšŒì˜ë¡ì— ëŒ€í•œ ì™„ì „í•œ ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ìƒì„±"""
        
        # Stage 1: ì´ˆê¸° ë…¸ì…˜ ì‘ë‹µ ìƒì„±
        print("      ğŸ¯ Stage 1: ì´ˆê¸° ë…¸ì…˜ í”„ë¡œì íŠ¸ ìƒì„±...", flush=True)
        initial_notion = self.generate_initial_notion_response(meeting_transcript)
        if not initial_notion["success"]:
            return {"success": False, "error": f"Stage 1 ì‹¤íŒ¨: {initial_notion['error']}"}
        
        # Stage 2: ì´ˆê¸° ì‘ë‹µ í‰ê°€
        print("      ğŸ“Š Stage 2: ì´ˆê¸° ì‘ë‹µ í’ˆì§ˆ í‰ê°€...")
        evaluation = self.evaluate_notion_response(meeting_transcript, initial_notion["result"])
        if not evaluation["success"]:
            return {"success": False, "error": f"Stage 2 ì‹¤íŒ¨: {evaluation['error']}"}
        
        iterations_used = 1
        final_notion = initial_notion["result"]
        current_score = evaluation["result"].get("overall_score", 0)
        
        # Stage 3: 7ì  ì´ìƒ ë  ë•Œê¹Œì§€ ë°˜ë³µ ê°œì„  (ìµœëŒ€ 3íšŒ)
        max_iterations = 3
        while current_score < 7.0 and iterations_used < max_iterations:
            print(f"      âš¡ Stage 3: ì‘ë‹µ ê°œì„  ì¤‘... (ì‹œë„ {iterations_used}, í˜„ì¬ ì ìˆ˜: {current_score}/10)")
            refined_notion = self.refine_notion_response(
                meeting_transcript, 
                final_notion, 
                evaluation["result"]
            )
            if not refined_notion["success"]:
                print(f"      âš ï¸ ê°œì„  ì‹¤íŒ¨, ê¸°ì¡´ ê²°ê³¼ ì‚¬ìš©: {refined_notion.get('error', 'Unknown error')}")
                break
            
            final_notion = refined_notion["result"]
            iterations_used += 1
            
            # ê°œì„ ëœ ê²°ê³¼ ì¬í‰ê°€
            print(f"      ğŸ“Š ê°œì„  ê²°ê³¼ ì¬í‰ê°€ ì¤‘...")
            re_evaluation = self.evaluate_notion_response(meeting_transcript, final_notion)
            if re_evaluation["success"]:
                current_score = re_evaluation["result"].get("overall_score", 0)
                print(f"      ğŸ“ˆ ê°œì„  í›„ ì ìˆ˜: {current_score}/10")
            else:
                print(f"      âš ï¸ ì¬í‰ê°€ ì‹¤íŒ¨, ì´ì „ ì ìˆ˜ ìœ ì§€")
                break
        
        if current_score >= 7.0:
            print(f"      âœ… Stage 3: ëª©í‘œ í’ˆì§ˆ ë‹¬ì„±! (ìµœì¢… ì ìˆ˜: {current_score}/10, ë°˜ë³µ íšŸìˆ˜: {iterations_used})")
        else:
            print(f"      âš ï¸ Stage 3: ìµœëŒ€ ì‹œë„ í›„ì—ë„ ëª©í‘œ ë¯¸ë‹¬ (ìµœì¢… ì ìˆ˜: {current_score}/10, ë°˜ë³µ íšŸìˆ˜: {iterations_used})")
        
        # Stage 4: PRD ìƒì„±
        print("      ğŸ“‹ Stage 4: PRD ìƒì„±...")
        prd_result = self.generate_prd_from_notion(final_notion)
        if not prd_result["success"]:
            return {"success": False, "error": f"Stage 4 ì‹¤íŒ¨: {prd_result['error']}"}
        
        # Stage 5: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬
        print("      ğŸ” Stage 5: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬...")
        final_quality = self.final_quality_check(final_notion, prd_result["result"])
        if not final_quality["success"]:
            return {"success": False, "error": f"Stage 5 ì‹¤íŒ¨: {final_quality['error']}"}
        
        return {
            "success": True,
            "notion_result": final_notion,
            "prd_result": prd_result["result"],
            "final_quality": final_quality["result"],
            "iterations_used": iterations_used
        }

def split_train_val(file_paths: List[str], train_ratio: float = 0.8) -> tuple:
    """íŒŒì¼ì„ í•™ìŠµ/ê²€ì¦ìš©ìœ¼ë¡œ ë¶„í• """
    import random
    random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
    
    shuffled_paths = file_paths.copy()
    random.shuffle(shuffled_paths)
    
    split_idx = int(len(shuffled_paths) * train_ratio)
    train_files = shuffled_paths[:split_idx]
    val_files = shuffled_paths[split_idx:]
    
    return train_files, val_files

def get_dir_name_from_path(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œì—ì„œ ë””ë ‰í† ë¦¬ ì´ë¦„ ì¶”ì¶œ"""
    return os.path.basename(os.path.dirname(file_path))

def print_processing_summary(processing_stats: Dict):
    """ì²˜ë¦¬ ìš”ì•½ ì¶œë ¥"""
    if processing_stats['processed'] > 0:
        print(f"   ğŸ“ˆ ì²˜ë¦¬ ì™„ë£Œ: {processing_stats['processed']}ê°œ")
        print(f"   âœ… ì„±ê³µ: {processing_stats['success']}ê°œ")
        print(f"   âŒ ì‹¤íŒ¨: {processing_stats['failed']}ê°œ")
        print(f"   ğŸ“ˆ ì„±ê³µë¥ : {processing_stats['success']/processing_stats['processed']*100:.1f}%")

def process_dataset_batch(generator: TtalkkakGoldStandardGenerator, 
                         data_dirs: List[str], 
                         dataset_type: str,
                         stats: Dict,
                         main_results_dir: Path) -> List[Dict]:
    """ë°ì´í„°ì…‹ ë°°ì¹˜ ì²˜ë¦¬ - ê° íŒŒì¼ë³„ ê°œë³„ ê²°ê³¼ í´ë” ìƒì„±"""
    dataset = []
    
    for i, file_path in enumerate(data_dirs):
        dir_name = get_dir_name_from_path(file_path)
        print(f"   ğŸ“ [{i+1}/{len(data_dirs)}] {dir_name} ì²˜ë¦¬ ì¤‘...", flush=True)
        
        # ê° íŒŒì¼ë³„ ê°œë³„ ê²°ê³¼ í´ë” ìƒì„±
        file_result_dir = main_results_dir / f"{dataset_type}_{i+1:03d}_{dir_name}"
        file_result_dir.mkdir(exist_ok=True)
        
        try:
            meeting_data = generator.load_meeting_data(file_path)
            if not meeting_data:
                stats["failed"] += 1
                print(f"      ğŸ’¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                continue
            
            meeting_transcript = meeting_data["transcript"]
            metadata = meeting_data["metadata"]
            
            print(f"      ğŸ”„ 5ë‹¨ê³„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
            
            result = generator.generate_gold_standard_sample(meeting_transcript, metadata)
            stats["processed"] += 1
            
            if result["success"]:
                quality_score = result["final_quality"].get("final_score", 0)
                is_production_ready = result["final_quality"].get("is_production_ready", False)
                
                print(f"      ğŸ“Š ìµœì¢… í’ˆì§ˆ: {quality_score}/10, í”„ë¡œë•ì…˜ ì¤€ë¹„: {is_production_ready}")
                
                # í’ˆì§ˆ ì ìˆ˜ ê´€ê³„ì—†ì´ ëª¨ë“  ê²°ê³¼ ì €ì¥
                is_high_quality = quality_score >= 7.0
                
                # ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥ (LLM ì¶œë ¥ë§Œ)
                individual_result = {
                    "id": f"{dataset_type}_{i+1:03d}",
                    "source_dir": dir_name,
                    "notion_output": result["notion_result"],
                    "prd_output": result["prd_result"],
                    "quality_metrics": {
                        "final_score": quality_score,
                        "is_production_ready": is_production_ready,
                        "iterations_used": result["iterations_used"],
                        "is_high_quality": is_high_quality
                    },
                    "metadata": {
                        **metadata,
                        "dataset_type": dataset_type,
                        "processing_date": datetime.now().isoformat()
                    }
                }
                
                # ê°œë³„ ê²°ê³¼ íŒŒì¼ ì €ì¥
                individual_file = file_result_dir / "result.json"
                with open(individual_file, 'w', encoding='utf-8') as f:
                    json.dump(individual_result, f, ensure_ascii=False, indent=2)
                
                # ì „ì²´ ë°ì´í„°ì…‹ì—ë„ ì¶”ê°€
                dataset.append(individual_result)
                stats["success"] += 1
                
                quality_status = "âœ… ê³ í’ˆì§ˆ" if is_high_quality else "âš ï¸ ì €í’ˆì§ˆ"
                print(f"      {quality_status} ì €ì¥ ì™„ë£Œ (í’ˆì§ˆ: {quality_score}/10) -> {file_result_dir}/result.json")
                print(f"      ğŸ“ íŒŒì¼ ê²½ë¡œ: {individual_file}")
                print(f"      ğŸ“„ íŒŒì¼ ì¡´ì¬ í™•ì¸: {individual_file.exists()}")
            else:
                stats["failed"] += 1
                print(f"      ğŸ’¥ ìƒì„± ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            stats["failed"] += 1
            stats["processed"] += 1
            print(f"      ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return dataset

def save_final_datasets(train_dataset: List[Dict], val_dataset: List[Dict], stats: Dict, results_dir: Path):
    """ìµœì¢… ë°ì´í„°ì…‹ ë° í†µê³„ ì €ì¥"""
    
    train_file = results_dir / "ttalkkac_train_gold_standard.json"
    val_file = results_dir / "ttalkkac_val_gold_standard.json"
    
    # í•™ìŠµ ë°ì´í„° ì €ì¥
    with open(train_file, 'w', encoding='utf-8') as f:
        json.dump(train_dataset, f, ensure_ascii=False, indent=2)
    
    # ê²€ì¦ ë°ì´í„° ì €ì¥
    with open(val_file, 'w', encoding='utf-8') as f:
        json.dump(val_dataset, f, ensure_ascii=False, indent=2)
    
    # í†µê³„ ê³„ì‚° ë° ì €ì¥
    if train_dataset:
        train_quality_avg = sum(s["quality_metrics"]["final_score"] for s in train_dataset) / len(train_dataset)
        train_lengths = [s["metadata"]["transcript_length"] for s in train_dataset]
    else:
        train_quality_avg = 0
        train_lengths = []
        
    if val_dataset:
        val_quality_avg = sum(s["quality_metrics"]["final_score"] for s in val_dataset) / len(val_dataset)
        val_lengths = [s["metadata"]["transcript_length"] for s in val_dataset]
    else:
        val_quality_avg = 0
        val_lengths = []
    
    final_stats = {
        **stats,
        "end_time": datetime.now().isoformat(),
        "final_train_count": len(train_dataset),
        "final_val_count": len(val_dataset),
        "train_quality_average": train_quality_avg,
        "val_quality_average": val_quality_avg,
        "train_length_stats": {
            "min": min(train_lengths) if train_lengths else 0,
            "max": max(train_lengths) if train_lengths else 0,
            "avg": sum(train_lengths) / len(train_lengths) if train_lengths else 0
        },
        "val_length_stats": {
            "min": min(val_lengths) if val_lengths else 0,
            "max": max(val_lengths) if val_lengths else 0,
            "avg": sum(val_lengths) / len(val_lengths) if val_lengths else 0
        }
    }
    
    stats_file = results_dir / "ttalkkac_generation_statistics.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(final_stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤ ({results_dir}):")
    print(f"   ğŸ“š ttalkkac_train_gold_standard.json ({len(train_dataset)}ê°œ ìƒ˜í”Œ)")
    print(f"   ğŸ” ttalkkac_val_gold_standard.json ({len(val_dataset)}ê°œ ìƒ˜í”Œ)")
    print(f"   ğŸ“Š ttalkkac_generation_statistics.json")
    print(f"   ğŸ“‚ ê°œë³„ ê²°ê³¼ í´ë”ë“¤: train_xxx_*, val_xxx_*")
    print(f"\nğŸ“ˆ í’ˆì§ˆ í†µê³„:")
    print(f"   í•™ìŠµ ë°ì´í„° í‰ê·  í’ˆì§ˆ: {train_quality_avg:.2f}/10")
    print(f"   ê²€ì¦ ë°ì´í„° í‰ê·  í’ˆì§ˆ: {val_quality_avg:.2f}/10")

if __name__ == "__main__":
    # Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì • (ì•ˆì „í•œ ë°©ì‹)
    import sys
    import locale
    
    # ì¶œë ¥ ë²„í¼ë§ ë¹„í™œì„±í™”ë¡œ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥
    sys.stdout.reconfigure(line_buffering=True)
    sys.stderr.reconfigure(line_buffering=True)
    
    # í•œê¸€ ì¶œë ¥ì„ ìœ„í•œ ì¸ì½”ë”© ì„¤ì •
    if sys.platform == "win32":
        try:
            sys.stdout.reconfigure(encoding='utf-8')
            sys.stderr.reconfigure(encoding='utf-8')
        except:
            # fallback: ê¸°ë³¸ ì¸ì½”ë”© ì‚¬ìš©
            pass
    
    # OpenAI API í‚¤ ì„¤ì •
    API_KEY = os.getenv("OPENAI_API_KEY")
    if not API_KEY:
        # ì§ì ‘ API í‚¤ ì„¤ì • (ì„ì‹œ)
        API_KEY = "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"
        print("API key set directly in code")
    
    if not API_KEY:
        print("ERROR: OPENAI_API_KEY environment variable not set.")
        print("Windows: set OPENAI_API_KEY=your_api_key_here")
        print("Linux/Mac: export OPENAI_API_KEY=your_api_key_here")
        exit(1)
    
    print("ğŸš€ TtalKkac ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘!")
    print("=" * 60)
    
    # ë©”ì¸ ê²°ê³¼ í´ë” ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    main_results_dir = Path(f"ttalkkac_gold_standard_results_{timestamp}")
    main_results_dir.mkdir(exist_ok=True)
    print(f"ğŸ“‚ ë©”ì¸ ê²°ê³¼ í´ë”: {main_results_dir}")
    
    # ì²˜ë¦¬ í†µê³„
    stats = {
        "start_time": datetime.now().isoformat(),
        "processed": 0,
        "success": 0,
        "failed": 0
    }
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = TtalkkakGoldStandardGenerator(api_key=API_KEY)
    
    # íšŒì˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
    meeting_files = generator.get_meeting_files("../batch_triplet_results")
    if not meeting_files:
        print("âŒ batch_triplet_results í´ë”ì—ì„œ 05_final_result.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    print(f"ğŸ“Š ë°œê²¬ëœ íšŒì˜ íŒŒì¼: {len(meeting_files)}ê°œ")
    
    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
    train_dirs, val_dirs = split_train_val(meeting_files, train_ratio=0.8)
    print(f"ğŸ“š í•™ìŠµìš©: {len(train_dirs)}ê°œ")
    print(f"ğŸ” ê²€ì¦ìš©: {len(val_dirs)}ê°œ")
    
    # ê²°ê³¼ ì €ì¥ìš©
    train_dataset = []
    val_dataset = []
    
    print(f"\nğŸ“š í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
    print("=" * 40)
    train_dataset = process_dataset_batch(generator, train_dirs, "train", stats, main_results_dir)
    
    print(f"\nğŸ” ê²€ì¦ ë°ì´í„° ìƒì„± ì¤‘...")
    print("=" * 40)
    val_dataset = process_dataset_batch(generator, val_dirs, "val", stats, main_results_dir)
    
    # ìµœì¢… ì €ì¥
    print(f"\nğŸ’¾ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì¤‘...")
    save_final_datasets(train_dataset, val_dataset, stats, main_results_dir)
    
    print(f"\nâœ… ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ìƒì„± ì™„ë£Œ!")
    print("=" * 60)