# TtalKkac AI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê°œì„ ì•ˆ (BERT í•„í„°ë§ ì ìš©)

## ğŸ¯ **ê¸°ì¡´ vs ê°œì„ ëœ íŒŒì´í”„ë¼ì¸**

### **ê¸°ì¡´ íŒŒì´í”„ë¼ì¸:**
```
ìŒì„± ì…ë ¥ â†’ WhisperX STT â†’ Qwen3 LLM â†’ ì—…ë¬´ ìƒì„±
```

### **ê°œì„ ëœ íŒŒì´í”„ë¼ì¸ (BERT í•„í„°ë§ ì¶”ê°€):**
```
ìŒì„± ì…ë ¥ â†’ WhisperX STT â†’ Triplet ìƒì„± â†’ BERT í•„í„°ë§ â†’ Qwen3 LLM â†’ ì—…ë¬´ ìƒì„±
```

---

## ğŸ” **ë‹¨ê³„ë³„ ìƒì„¸ ì²˜ë¦¬ ê³¼ì •**

### **1ë‹¨ê³„: WhisperX ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜**
```python
# ê¸°ì¡´ê³¼ ë™ì¼
whisper_result = whisperx.transcribe(audio_file, language="ko")
segments = whisper_result["segments"]
```

### **2ë‹¨ê³„: ë°œí™” ë°ì´í„° êµ¬ì¡°í™”** âœ¨ **NEW**
```python
# whisperX_parser.py í™œìš©
structured_data = parse_whisperx_json(whisper_json_path)
# ê²°ê³¼: [{"timestamp", "speaker", "text", "timestamp_order"}]
```

### **3ë‹¨ê³„: Triplet ìƒì„±** âœ¨ **NEW**
```python
# create_triplets.py í™œìš©
triplets = create_structured_triplets(structured_data)
# ê²°ê³¼: [{"prev", "target", "next", "speaker", "timestamp"}]
```

### **4ë‹¨ê³„: BERT ê¸°ë°˜ ì¤‘ìš”ë„ ë¶„ë¥˜** âœ¨ **NEW**
```python
# BERT ëª¨ë¸ ì¶”ë¡  (klue/bert-base ë“± í•œêµ­ì–´ ëª¨ë¸)
for triplet in triplets:
    input_text = f"{triplet['prev']} {triplet['target']} {triplet['next']}"
    label = bert_classifier.predict(input_text)  # 0: ì¤‘ìš”, 1: ë¶ˆí•„ìš”
    triplet['label'] = label
```

### **5ë‹¨ê³„: ì¤‘ìš” ë°œí™” í•„í„°ë§** âœ¨ **NEW**
```python
# triplet_preprocessor.py í™œìš©
important_speeches = preprocess_triplets(triplets_with_labels)
# ê²°ê³¼: label=0ì¸ ì¤‘ìš” ë°œí™”ë§Œ ì¶”ì¶œ
```

### **6ë‹¨ê³„: Qwen3 LLM ì—…ë¬´ ìƒì„±**
```python
# í•„í„°ë§ëœ ì¤‘ìš” ë°œí™”ë§Œ LLMì— ì…ë ¥
filtered_text = "\n".join([speech["text"] for speech in important_speeches])
tasks = qwen3_model.generate_tasks(filtered_text)
```

---

## ğŸ“Š **ì˜ˆìƒ íš¨ê³¼ ë° ì¥ì **

### **1. ì²˜ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ**
- **ê¸°ì¡´**: ì „ì²´ íšŒì˜ ë‚´ìš©ì„ LLMì— ì…ë ¥ (í† í° ë‚­ë¹„)
- **ê°œì„ **: ì¤‘ìš” ë°œí™”ë§Œ ì„ ë³„í•˜ì—¬ ì…ë ¥ (30-50% í† í° ì ˆì•½)

### **2. ì—…ë¬´ ìƒì„± í’ˆì§ˆ í–¥ìƒ**
- **ë…¸ì´ì¦ˆ ì œê±°**: ì¡ë‹´, ì¸ì‚¬ë§, ë°˜ë³µ ë°œì–¸ ë“± ì œì™¸
- **í•µì‹¬ ì§‘ì¤‘**: í”„ë¡œì íŠ¸ ê´€ë ¨ í•µì‹¬ ë‚´ìš©ë§Œ ë¶„ì„
- **ì •í™•ë„ í–¥ìƒ**: ë¶ˆí•„ìš”í•œ ì •ë³´ë¡œ ì¸í•œ í˜¼ë€ ë°©ì§€

### **3. ë¹„ìš© ìµœì í™”**
- **LLM í˜¸ì¶œ ë¹„ìš©**: 30-50% ì ˆê° (ì…ë ¥ í† í° ê°ì†Œ)
- **ì²˜ë¦¬ ì‹œê°„**: 20-30% ë‹¨ì¶• (ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°)
- **GPU ì‚¬ìš©ëŸ‰**: BERT ì¶”ë¡ ì€ CPUë¡œë„ ì¶©ë¶„íˆ ë¹ ë¦„

---

## ğŸ› ï¸ **êµ¬í˜„ ë°©ì•ˆ**

### **A. BERT ëª¨ë¸ ì„ íƒ**
```python
# í•œêµ­ì–´ íŠ¹í™” BERT ëª¨ë¸ í›„ë³´
models = [
    "klue/bert-base",           # KLUE í•œêµ­ì–´ BERT
    "beomi/kcbert-base",        # í•œêµ­ì–´ ì»¤ë®¤ë‹ˆí‹° BERT  
    "monologg/kobert",          # SKT KoBERT
]
```

### **B. í•™ìŠµ ë°ì´í„° êµ¬ì„±**
```python
# íšŒì˜ ë°œí™” ë¶„ë¥˜ ë°ì´í„°ì…‹
training_data = [
    # Label 0: ì—…ë¬´ ê´€ë ¨ ì¤‘ìš” ë°œí™”
    {"text": "ì´ë²ˆ ì£¼ê¹Œì§€ ë¡œê·¸ì¸ ê¸°ëŠ¥ ê°œë°œ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤", "label": 0},
    {"text": "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ë¨¼ì € ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤", "label": 0},
    
    # Label 1: ë¶ˆí•„ìš”í•œ ë°œí™”
    {"text": "ì•ˆë…•í•˜ì„¸ìš” ëª¨ë‘ë“¤ ì˜ ì§€ë‚´ì…¨ë‚˜ìš”", "label": 1},
    {"text": "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”", "label": 1},
]
```

### **C. ëª¨ë¸ íŒŒì¸íŠœë‹**
```python
# Hugging Face Transformers í™œìš©
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")
model = AutoModelForSequenceClassification.from_pretrained(
    "klue/bert-base", 
    num_labels=2  # 0: ì¤‘ìš”, 1: ë¶ˆí•„ìš”
)

# íšŒì˜ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹
trainer.train(training_data)
```

---

## ğŸ”§ **TtalKkac í†µí•© êµ¬í˜„**

### **1. AI Engine êµ¬ì¡° ë³€ê²½**
```python
# ai-engine/processors/bert/
class MeetingContentClassifier:
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")
        self.model = AutoModelForSequenceClassification.from_pretrained(
            "./models/meeting-classifier"  # íŒŒì¸íŠœë‹ëœ ëª¨ë¸
        )
    
    def classify_triplets(self, triplets):
        # Tripletë³„ ì¤‘ìš”ë„ ë¶„ë¥˜
        for triplet in triplets:
            input_text = f"{triplet['prev']} {triplet['target']} {triplet['next']}"
            prediction = self.predict(input_text)
            triplet['label'] = prediction
        return triplets
```

### **2. Handler ì—…ë°ì´íŠ¸**
```python
# ai-engine-runpod/handler.py ìˆ˜ì •
def process_meeting(audio_file):
    # 1. WhisperX ìŒì„±ì¸ì‹
    whisper_result = whisperx_processor.transcribe(audio_file)
    
    # 2. êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„± âœ¨ NEW
    structured_data = parse_whisperx_json(whisper_result)
    
    # 3. Triplet ìƒì„± âœ¨ NEW
    triplets = create_structured_triplets(structured_data)
    
    # 4. BERT ë¶„ë¥˜ âœ¨ NEW
    classified_triplets = bert_classifier.classify_triplets(triplets)
    
    # 5. ì¤‘ìš” ë°œí™” í•„í„°ë§ âœ¨ NEW
    important_speeches = preprocess_triplets(classified_triplets)
    
    # 6. Qwen3 ì—…ë¬´ ìƒì„± (ê¸°ì¡´)
    filtered_text = format_important_speeches(important_speeches)
    tasks = qwen3_model.generate_tasks(filtered_text)
    
    return {
        "transcription": whisper_result,
        "important_speeches": important_speeches,
        "generated_tasks": tasks,
        "processing_stats": {
            "total_speeches": len(triplets),
            "important_speeches": len(important_speeches),
            "filtering_ratio": len(important_speeches) / len(triplets)
        }
    }
```

### **3. Backend API ì—°ë™**
```typescript
// backend/src/services/ai-service.ts ì—…ë°ì´íŠ¸
interface ProcessedMeeting {
  transcription: WhisperResult;
  importantSpeeches: ImportantSpeech[];  // âœ¨ NEW
  generatedTasks: Task[];
  processingStats: {                     // âœ¨ NEW
    totalSpeeches: number;
    importantSpeeches: number;
    filteringRatio: number;
  };
}

async function processMeetingWithBERT(audioFile: File): Promise<ProcessedMeeting> {
  // RunPod GPU Cloud í˜¸ì¶œ (BERT í•„í„°ë§ í¬í•¨)
  const response = await runpodClient.post('/process-meeting-enhanced', {
    audio: audioFile
  });
  
  return response.data;
}
```

---

## ğŸ“ˆ **ì„±ëŠ¥ ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§**

### **ì¶”ê°€ ë©”íŠ¸ë¦­**
```typescript
interface AIProcessingMetrics {
  // ê¸°ì¡´ ë©”íŠ¸ë¦­
  whisperProcessingTime: number;
  qwenProcessingTime: number;
  totalTokensUsed: number;
  
  // ìƒˆë¡œìš´ BERT ê´€ë ¨ ë©”íŠ¸ë¦­ âœ¨ NEW
  bertProcessingTime: number;
  totalSpeeches: number;
  importantSpeeches: number;
  filteringRatio: number;        // ì¤‘ìš” ë°œí™” ë¹„ìœ¨
  tokenSavingRatio: number;      // í† í° ì ˆì•½ ë¹„ìœ¨
  bertAccuracy: number;          // BERT ë¶„ë¥˜ ì •í™•ë„ (ê²€ì¦ ì‹œ)
}
```

---

## ğŸ¯ **ë‹¨ê³„ì  ë„ì… ê³„íš**

### **Phase 1: BERT ëª¨ë¸ ì¤€ë¹„** (2ì£¼)
1. í•œêµ­ì–´ BERT ëª¨ë¸ ì„ íƒ ë° í™˜ê²½ êµ¬ì„±
2. íšŒì˜ ë°œí™” ë¶„ë¥˜ ë°ì´í„°ì…‹ êµ¬ì¶• (1000ê°œ ìƒ˜í”Œ)
3. ëª¨ë¸ íŒŒì¸íŠœë‹ ë° ì„±ëŠ¥ ê²€ì¦

### **Phase 2: íŒŒì´í”„ë¼ì¸ í†µí•©** (2ì£¼)
1. WhisperX â†’ BERT â†’ Qwen3 íŒŒì´í”„ë¼ì¸ êµ¬í˜„
2. RunPod í™˜ê²½ì—ì„œ í†µí•© í…ŒìŠ¤íŠ¸
3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ìµœì í™”

### **Phase 3: í”„ë¡œë•ì…˜ ë°°í¬** (1ì£¼)
1. Backend API ì—°ë™ ë° í”„ë¡ íŠ¸ì—”ë“œ ì—…ë°ì´íŠ¸
2. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì— ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€
3. A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ íš¨ê³¼ ê²€ì¦

---

## ğŸ’¡ **ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´**

### **1. ë‹¤ë‹¨ê³„ í•„í„°ë§**
```python
# í™”ìë³„ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ì ìš©
speaker_weights = {
    "íŒ€ì¥": 1.2,      # íŒ€ì¥ ë°œì–¸ì€ ì¤‘ìš”ë„ ë†’ê²Œ
    "PM": 1.1,        # PM ë°œì–¸ë„ ì¤‘ìš”
    "ê°œë°œì": 1.0,    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
}
```

### **2. ì‹¤ì‹œê°„ í•™ìŠµ**
```python
# ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ê°œì„ 
def update_model_with_feedback(user_feedback):
    # ì‚¬ìš©ìê°€ "ì´ê±´ ì¤‘ìš”í•œ ë°œí™”ì˜€ëŠ”ë° ë†“ì³¤ë„¤ìš”" í”¼ë“œë°± ì‹œ
    # ëª¨ë¸ ì¬í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©
    pass
```

### **3. ë‹¤êµ­ì–´ ì§€ì›**
```python
# ì–¸ì–´ë³„ BERT ëª¨ë¸ ìë™ ì„ íƒ
language_models = {
    "ko": "klue/bert-base",
    "en": "bert-base-uncased", 
    "ja": "cl-tohoku/bert-base-japanese"
}
```

ì´ëŸ¬í•œ BERT ê¸°ë°˜ í•„í„°ë§ ì‹œìŠ¤í…œì„ ë„ì…í•˜ë©´ **TtalKkacì˜ AI ì²˜ë¦¬ í’ˆì§ˆê³¼ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒ**ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤! ğŸš€ 