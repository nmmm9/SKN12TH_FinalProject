# TtalKkacì— ëˆ„ë½ëœ BERT ë¶„ë¥˜ êµ¬í˜„ ë°©ì•ˆ

## ğŸ” **í˜„ì¬ ìƒí™© ë¶„ì„**

ì œê³µë°›ì€ 3ê°œ íŒŒì¼(`whisperX_parser.py`, `create_triplets.py`, `triplet_preprocessor.py`)ì€ **BERT íŒŒì´í”„ë¼ì¸ì˜ ì „í›„ ì²˜ë¦¬**ë§Œ ë‹´ë‹¹í•˜ê³ , **í•µì‹¬ì¸ BERT ë¶„ë¥˜ ë‹¨ê³„ê°€ ì™„ì „íˆ ëˆ„ë½**ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### **í˜„ì¬ ì½”ë“œì˜ ë¬¸ì œì **
```python
# create_triplets.pyì—ì„œ
result.append({
    # ... ë‹¤ë¥¸ í•„ë“œë“¤ ...
    "label": None  # âŒ ë¼ë²¨ì´ Noneìœ¼ë¡œ ì„¤ì •ë¨
})

# triplet_preprocessor.pyì—ì„œ
for triplet in triplets_with_labels:  # âŒ ë¼ë²¨ì´ ì–´ë””ì„œ ì™”ëŠ”ì§€ ë¶ˆë¶„ëª…
    if triplet["label"] == 0:
        # ì¤‘ìš” ë°œí™” ì²˜ë¦¬
```

## ğŸ› ï¸ **ëˆ„ë½ëœ BERT ë¶„ë¥˜ ë‹¨ê³„ êµ¬í˜„**

### **4. bert_classifier.py** (ìƒˆë¡œ í•„ìš”í•œ íŒŒì¼)

```python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class MeetingContentClassifier:
    """
    BERT ê¸°ë°˜ íšŒì˜ ë‚´ìš© ì¤‘ìš”ë„ ë¶„ë¥˜ê¸°
    Triplet êµ¬ì¡°ì˜ ë°œí™”ë¥¼ ë°›ì•„ì„œ ì¤‘ìš”ë„(0: ì¤‘ìš”, 1: ë¶ˆí•„ìš”)ë¥¼ ë¶„ë¥˜
    """
    
    def __init__(self, model_path: str = "klue/bert-base"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_path,
            num_labels=2  # 0: ì¤‘ìš”, 1: ë¶ˆí•„ìš”
        ).to(self.device)
        
        logger.info(f"âœ… BERT ë¶„ë¥˜ê¸° ë¡œë“œ ì™„ë£Œ: {model_path} on {self.device}")
    
    def classify_single_triplet(self, triplet: Dict) -> int:
        """ë‹¨ì¼ triplet ë¶„ë¥˜"""
        # Triplet í…ìŠ¤íŠ¸ êµ¬ì„±: [ì´ì „ë§¥ë½] + [í˜„ì¬ë°œí™”] + [ë‹¤ìŒë§¥ë½]
        input_text = f"{triplet['prev']} {triplet['target']} {triplet['next']}"
        
        # í† í°í™”
        inputs = self.tokenizer(
            input_text,
            max_length=512,
            padding=True,
            truncation=True,
            return_tensors="pt"
        ).to(self.device)
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_label = torch.argmax(predictions, dim=-1).item()
        
        return predicted_label
    
    def classify_triplets(self, triplets: List[Dict]) -> List[Dict]:
        """Triplet ë¦¬ìŠ¤íŠ¸ ì¼ê´„ ë¶„ë¥˜"""
        logger.info(f"ğŸ§  BERT ë¶„ë¥˜ ì‹œì‘: {len(triplets)}ê°œ triplet")
        
        for i, triplet in enumerate(triplets):
            label = self.classify_single_triplet(triplet)
            triplet['label'] = label
            
            if (i + 1) % 10 == 0:
                logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(triplets)} ({(i+1)/len(triplets)*100:.1f}%)")
        
        # í†µê³„ ê³„ì‚°
        important_count = sum(1 for t in triplets if t['label'] == 0)
        total_count = len(triplets)
        
        logger.info(f"âœ… BERT ë¶„ë¥˜ ì™„ë£Œ: {important_count}/{total_count} ({important_count/total_count*100:.1f}%) ì¤‘ìš” ë°œí™”")
        
        return triplets
```

### **5. complete_pipeline.py** (í†µí•© íŒŒì´í”„ë¼ì¸)

```python
from whisperX_parser import parse_whisperx_json
from create_triplets import create_structured_triplets
from bert_classifier import MeetingContentClassifier
from triplet_preprocessor import preprocess_triplets
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class CompleteMeetingPipeline:
    """
    ì™„ì „í•œ íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸
    WhisperX â†’ Triplet ìƒì„± â†’ BERT ë¶„ë¥˜ â†’ ì¤‘ìš” ë°œí™” í•„í„°ë§
    """
    
    def __init__(self, bert_model_path: str = "klue/bert-base"):
        self.bert_classifier = MeetingContentClassifier(bert_model_path)
        logger.info("ğŸš€ ì™„ì „í•œ íšŒì˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_meeting(self, whisper_json_path: str, log_file_path: str = None) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"ğŸ“ íšŒì˜ ë¶„ì„ ì‹œì‘: {whisper_json_path}")
        
        # 1ë‹¨ê³„: WhisperX ê²°ê³¼ íŒŒì‹±
        logger.info("1ï¸âƒ£ WhisperX ê²°ê³¼ íŒŒì‹± ì¤‘...")
        structured_data = parse_whisperx_json(whisper_json_path)
        
        # 2ë‹¨ê³„: Triplet ìƒì„±
        logger.info("2ï¸âƒ£ Triplet êµ¬ì¡° ìƒì„± ì¤‘...")
        triplets = create_structured_triplets(structured_data)
        
        # 3ë‹¨ê³„: BERT ë¶„ë¥˜ âœ¨ í•µì‹¬ ë‹¨ê³„!
        logger.info("3ï¸âƒ£ BERT ì¤‘ìš”ë„ ë¶„ë¥˜ ì¤‘...")
        classified_triplets = self.bert_classifier.classify_triplets(triplets)
        
        # 4ë‹¨ê³„: ì¤‘ìš” ë°œí™” í•„í„°ë§
        logger.info("4ï¸âƒ£ ì¤‘ìš” ë°œí™” í•„í„°ë§ ì¤‘...")
        important_speeches = preprocess_triplets(classified_triplets, log_file_path)
        
        # ê²°ê³¼ í†µê³„
        total_triplets = len(triplets)
        important_triplets = len(important_speeches)
        filtering_ratio = important_triplets / total_triplets if total_triplets > 0 else 0
        
        result = {
            "total_speeches": total_triplets,
            "important_speeches": important_triplets,
            "filtering_ratio": filtering_ratio,
            "filtered_content": important_speeches,
            "processing_stats": {
                "total_segments": len(structured_data),
                "total_triplets": total_triplets,
                "important_triplets": important_triplets,
                "noise_reduction": 1 - filtering_ratio
            }
        }
        
        logger.info(f"âœ… íšŒì˜ ë¶„ì„ ì™„ë£Œ: {important_triplets}/{total_triplets} ({filtering_ratio*100:.1f}%) ì¤‘ìš” ë°œí™” ì¶”ì¶œ")
        
        return result

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    pipeline = CompleteMeetingPipeline("klue/bert-base")
    
    result = pipeline.process_meeting(
        whisper_json_path="meeting_transcription.json",
        log_file_path="filtered_out_speeches.jsonl"
    )
    
    print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
    print(f"- ì „ì²´ ë°œí™”: {result['total_speeches']}ê°œ")
    print(f"- ì¤‘ìš” ë°œí™”: {result['important_speeches']}ê°œ")
    print(f"- í•„í„°ë§ ë¹„ìœ¨: {result['filtering_ratio']*100:.1f}%")
```

## ğŸš€ **TtalKkac AI Engine í†µí•© ë°©ì•ˆ**

### **ai-engine/processors/bert/meeting_classifier.py**

```python
"""
TtalKkac BERT ê¸°ë°˜ íšŒì˜ ë‚´ìš© ë¶„ë¥˜ê¸°
ai-engineì— í†µí•©í•˜ì—¬ ì‚¬ìš©
"""

import os
import logging
from typing import List, Dict, Any
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

logger = logging.getLogger(__name__)

class TtalKkacMeetingClassifier:
    """TtalKkac ì „ìš© BERT ë¶„ë¥˜ê¸°"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_path = os.getenv("BERT_MODEL_PATH", "klue/bert-base")
        self.tokenizer = None
        self.model = None
        
    async def initialize(self):
        """ë¹„ë™ê¸° ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info(f"ğŸ§  BERT ë¶„ë¥˜ê¸° ì´ˆê¸°í™”: {self.model_path}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_path,
            num_labels=2
        ).to(self.device)
        
        logger.info(f"âœ… BERT ë¶„ë¥˜ê¸° ë¡œë“œ ì™„ë£Œ on {self.device}")
    
    async def classify_meeting_content(self, whisper_segments: List[Dict]) -> Dict[str, Any]:
        """íšŒì˜ ë‚´ìš© ë¶„ë¥˜ ë©”ì¸ í•¨ìˆ˜"""
        
        # 1. WhisperX ì„¸ê·¸ë¨¼íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        from whisperX_parser import parse_whisperx_json  # ê¸°ì¡´ íŒŒì¼ í™œìš©
        from create_triplets import create_structured_triplets
        from triplet_preprocessor import preprocess_triplets
        
        # ì„ì‹œ JSON íŒŒì¼ë¡œ ì €ì¥ í›„ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬ ê°€ëŠ¥)
        structured_data = self._convert_segments_to_structured_data(whisper_segments)
        
        # 2. Triplet ìƒì„±
        triplets = create_structured_triplets(structured_data)
        
        # 3. BERT ë¶„ë¥˜
        classified_triplets = await self._classify_triplets_async(triplets)
        
        # 4. ì¤‘ìš” ë°œí™” í•„í„°ë§
        important_speeches = preprocess_triplets(classified_triplets)
        
        return {
            "success": True,
            "total_speeches": len(triplets),
            "important_speeches": len(important_speeches),
            "filtering_ratio": len(important_speeches) / len(triplets),
            "filtered_content": important_speeches,
            "noise_reduction_stats": {
                "total_segments": len(whisper_segments),
                "total_triplets": len(triplets),
                "important_triplets": len(important_speeches),
                "filtered_out": len(triplets) - len(important_speeches)
            }
        }
    
    def _convert_segments_to_structured_data(self, segments: List[Dict]) -> List[Dict]:
        """WhisperX ì„¸ê·¸ë¨¼íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        structured_data = []
        for i, seg in enumerate(segments):
            structured_data.append({
                "timestamp": self._seconds_to_timestamp(seg.get("start", 0)),
                "timestamp_order": f"{i+1}-1",
                "speaker": seg.get("speaker", "UNKNOWN"),
                "text": seg.get("text", "").strip()
            })
        return structured_data
    
    def _seconds_to_timestamp(self, seconds: float) -> str:
        """ì´ˆë¥¼ HH:MM:SS í˜•íƒœë¡œ ë³€í™˜"""
        from datetime import timedelta
        td = timedelta(seconds=seconds)
        return str(td).split('.')[0].zfill(8)
    
    async def _classify_triplets_async(self, triplets: List[Dict]) -> List[Dict]:
        """ë¹„ë™ê¸° triplet ë¶„ë¥˜"""
        import asyncio
        
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        
        def classify_sync():
            for triplet in triplets:
                input_text = f"{triplet['prev']} {triplet['target']} {triplet['next']}"
                
                inputs = self.tokenizer(
                    input_text,
                    max_length=512,
                    padding=True,
                    truncation=True,
                    return_tensors="pt"
                ).to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    predicted_label = torch.argmax(outputs.logits, dim=-1).item()
                
                triplet['label'] = predicted_label
            
            return triplets
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë¹„ë™ê¸° ì²˜ë¦¬
        classified_triplets = await loop.run_in_executor(None, classify_sync)
        
        return classified_triplets

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
meeting_classifier = TtalKkacMeetingClassifier()
```

### **ai-engine/main.py ì—…ë°ì´íŠ¸**

```python
# ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€

from processors.bert.meeting_classifier import meeting_classifier

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    logger.info("ğŸš€ AI Engine ì‹œì‘ ì¤‘...")
    
    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
    await load_ai_models()
    
    # BERT ë¶„ë¥˜ê¸° ì´ˆê¸°í™” âœ¨ NEW
    await meeting_classifier.initialize()
    
    yield
    
    logger.info("ğŸ›‘ AI Engine ì¢…ë£Œ ì¤‘...")
    await cleanup_models()

@app.post("/stt/process-with-filtering")
async def process_audio_with_bert_filtering(
    request: AudioProcessRequest,
    background_tasks: BackgroundTasks
):
    """
    BERT í•„í„°ë§ì„ í¬í•¨í•œ STT ì²˜ë¦¬
    """
    try:
        logger.info(f"ğŸ§ BERT í•„í„°ë§ STT ì²˜ë¦¬ ì‹œì‘: {request.meeting_id}")
        
        # 1. ê¸°ë³¸ WhisperX STT ì²˜ë¦¬
        stt_result = await whisper_processor.process_audio_file(
            audio_url=request.audio_url,
            meeting_id=request.meeting_id,
            language=request.language
        )
        
        # 2. BERT ê¸°ë°˜ ì¤‘ìš” ë°œí™” í•„í„°ë§ âœ¨ NEW
        bert_result = await meeting_classifier.classify_meeting_content(
            stt_result["segments"]
        )
        
        # 3. í†µí•© ê²°ê³¼ ë°˜í™˜
        result = {
            "meeting_id": request.meeting_id,
            "tenant_id": request.tenant_id,
            
            # ê¸°ì¡´ STT ê²°ê³¼
            "transcript": stt_result["transcript"],
            "segments": stt_result["segments"],
            "speakers": stt_result["speakers"],
            
            # BERT í•„í„°ë§ ê²°ê³¼ âœ¨ NEW
            "filtered_transcript": " ".join([
                speech["text"] for speech in bert_result["filtered_content"]
            ]),
            "important_speeches": bert_result["filtered_content"],
            "filtering_stats": {
                "total_speeches": bert_result["total_speeches"],
                "important_speeches": bert_result["important_speeches"],
                "filtering_ratio": bert_result["filtering_ratio"],
                "noise_reduction": 1 - bert_result["filtering_ratio"]
            },
            
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°
            "processing_time": stt_result["processing_time"],
            "language": stt_result["language"]
        }
        
        logger.info(f"âœ… BERT í•„í„°ë§ STT ì²˜ë¦¬ ì™„ë£Œ: {request.meeting_id}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ BERT í•„í„°ë§ STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
```

## ğŸ¯ **ì˜ˆìƒ íš¨ê³¼**

### **1. ì²˜ë¦¬ í’ˆì§ˆ í–¥ìƒ**
- **ë…¸ì´ì¦ˆ ì œê±°**: ì¡ë‹´, ì¸ì‚¬ë§, ë°˜ë³µ ë°œì–¸ ë“± ìë™ í•„í„°ë§
- **í•µì‹¬ ì§‘ì¤‘**: ì—…ë¬´ ê´€ë ¨ ì¤‘ìš” ë‚´ìš©ë§Œ LLMì— ì „ë‹¬
- **ì •í™•ë„ í–¥ìƒ**: ë¶ˆí•„ìš”í•œ ì •ë³´ë¡œ ì¸í•œ LLM í˜¼ë€ ë°©ì§€

### **2. ë¹„ìš© íš¨ìœ¨ì„±**
- **í† í° ì ˆì•½**: 30-50% LLM ì…ë ¥ í† í° ê°ì†Œ
- **ì²˜ë¦¬ ì‹œê°„**: 20-30% ë‹¨ì¶•
- **GPU ë¹„ìš©**: BERTëŠ” CPUë¡œë„ ì¶©ë¶„íˆ ë¹ ë¦„

### **3. í™•ì¥ ê°€ëŠ¥ì„±**
- **ë‹¤êµ­ì–´ ì§€ì›**: ì–¸ì–´ë³„ BERT ëª¨ë¸ ìë™ ì„ íƒ
- **ë„ë©”ì¸ íŠ¹í™”**: ì—…ì¢…ë³„ íŒŒì¸íŠœë‹ ê°€ëŠ¥
- **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ê°œì„ 

## ğŸ“‹ **êµ¬í˜„ ìš°ì„ ìˆœìœ„**

### **Phase 1: ê¸°ë³¸ BERT í†µí•©** (1ì£¼)
1. `bert_classifier.py` êµ¬í˜„
2. ê¸°ì¡´ triplet íŒŒì¼ë“¤ê³¼ ì—°ë™
3. ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### **Phase 2: AI Engine í†µí•©** (1ì£¼)  
1. `ai-engine`ì— BERT í”„ë¡œì„¸ì„œ ì¶”ê°€
2. ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
3. Backend ì—°ë™ í…ŒìŠ¤íŠ¸

### **Phase 3: í”„ë¡œë•ì…˜ ë°°í¬** (1ì£¼)
1. RunPod í™˜ê²½ì— BERT ëª¨ë¸ ë°°í¬
2. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§
3. A/B í…ŒìŠ¤íŠ¸ë¡œ íš¨ê³¼ ê²€ì¦

ì´ì œ **ì™„ì „í•œ BERT íŒŒì´í”„ë¼ì¸**ì„ êµ¬í˜„í•˜ë©´ TtalKkacì˜ AI ì²˜ë¦¬ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒë  ê²ƒì…ë‹ˆë‹¤! ğŸš€ 