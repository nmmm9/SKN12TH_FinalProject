"""
RunPod GPU í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
WhisperX + FastAPI ì„œë²„ ìë™ ì„¤ì •
"""

import os
import subprocess
import sys
import time
import requests
from pathlib import Path

def run_command(command, description=""):
    """ëª…ë ¹ì–´ ì‹¤í–‰"""
    print(f"ğŸ”§ {description if description else command}")
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        if result.stdout:
            print(f"âœ… {result.stdout.strip()}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì‹¤íŒ¨: {e}")
        if e.stderr:
            print(f"ì˜¤ë¥˜: {e.stderr.strip()}")
        return False

def check_gpu():
    """GPU í™•ì¸"""
    print("ğŸ” GPU í™˜ê²½ í™•ì¸...")
    
    # NVIDIA GPU í™•ì¸
    if run_command("nvidia-smi", "NVIDIA GPU í™•ì¸"):
        print("âœ… NVIDIA GPU ê°ì§€ë¨")
    else:
        print("âš ï¸ NVIDIA GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # CUDA í™•ì¸
    if run_command("nvcc --version", "CUDA ë²„ì „ í™•ì¸"):
        print("âœ… CUDA ì„¤ì¹˜ í™•ì¸ë¨")
    else:
        print("âš ï¸ CUDAë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return True

def install_system_dependencies():
    """ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜"""
    print("ğŸ“¦ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜...")
    
    # ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
    run_command("apt-get update", "íŒ¨í‚¤ì§€ ëª©ë¡ ì—…ë°ì´íŠ¸")
    
    # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
    dependencies = [
        "ffmpeg",
        "libsndfile1",
        "portaudio19-dev",
        "python3-pyaudio",
        "build-essential",
        "git"
    ]
    
    for dep in dependencies:
        run_command(f"apt-get install -y {dep}", f"{dep} ì„¤ì¹˜")

def install_python_dependencies():
    """Python ì˜ì¡´ì„± ì„¤ì¹˜"""
    print("ğŸ Python ì˜ì¡´ì„± ì„¤ì¹˜...")
    
    # pip ì—…ê·¸ë ˆì´ë“œ
    run_command("pip install --upgrade pip", "pip ì—…ê·¸ë ˆì´ë“œ")
    
    # PyTorch ì„¤ì¹˜ (CUDA ì§€ì›)
    torch_command = "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
    run_command(torch_command, "PyTorch (CUDA) ì„¤ì¹˜")
    
    # WhisperX ì„¤ì¹˜
    run_command("pip install whisperx", "WhisperX ì„¤ì¹˜")
    
    # requirements.txtê°€ ìˆìœ¼ë©´ ì„¤ì¹˜
    if os.path.exists("requirements.txt"):
        run_command("pip install -r requirements.txt", "requirements.txt ì˜ì¡´ì„± ì„¤ì¹˜")
    else:
        # ê¸°ë³¸ ì˜ì¡´ì„±ë“¤ ì„¤ì¹˜
        basic_deps = [
            "fastapi[all]",
            "uvicorn[standard]",
            "python-multipart",
            "aiofiles",
            "librosa",
            "soundfile",
            "numpy",
            "scipy",
            "python-dotenv",
            "httpx",
            "websockets",
            "transformers",
            "accelerate"
        ]
        
        for dep in basic_deps:
            run_command(f"pip install {dep}", f"{dep} ì„¤ì¹˜")

def download_models():
    """AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ¤– AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ...")
    
    # WhisperX ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ
    try:
        import whisperx
        
        # Large-v3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print("ğŸ“¥ Whisper Large-v3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        model = whisperx.load_model("large-v3", device="cuda", compute_type="float16")
        print("âœ… Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        del model  # ë©”ëª¨ë¦¬ í•´ì œ
        
        # í•œêµ­ì–´ alignment ëª¨ë¸ ì‹œë„
        try:
            align_model, metadata = whisperx.load_align_model(language_code="ko", device="cuda")
            print("âœ… í•œêµ­ì–´ alignment ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            del align_model
        except Exception as e:
            print(f"âš ï¸ í•œêµ­ì–´ alignment ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # Diarization ëª¨ë¸ (HuggingFace í† í° í•„ìš”)
        hf_token = os.getenv("HF_TOKEN")
        if hf_token:
            try:
                diarize_model = whisperx.DiarizationPipeline(use_auth_token=hf_token, device="cuda")
                print("âœ… í™”ì ë¶„ë¦¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                del diarize_model
            except Exception as e:
                print(f"âš ï¸ í™”ì ë¶„ë¦¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("âš ï¸ HF_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•„ í™”ì ë¶„ë¦¬ ëª¨ë¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

def create_env_file():
    """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±"""
    print("âš™ï¸ í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±...")
    
    env_content = """# DdalKkak AI Engine í™˜ê²½ ë³€ìˆ˜
# HuggingFace í† í° (í™”ì ë¶„ë¦¬ìš©)
HF_TOKEN=your_huggingface_token_here

# GPU ì„¤ì •
CUDA_VISIBLE_DEVICES=0

# ë¡œê·¸ ë ˆë²¨
LOG_LEVEL=INFO

# ì„œë²„ ì„¤ì •
HOST=0.0.0.0
PORT=8001

# ê°œë°œ ëª¨ë“œ
DEBUG=True
"""
    
    with open(".env", "w") as f:
        f.write(env_content)
    
    print("âœ… .env íŒŒì¼ ìƒì„± ì™„ë£Œ")
    print("âš ï¸ HF_TOKENì„ ì‹¤ì œ í† í°ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”!")

def setup_service():
    """ì„œë¹„ìŠ¤ ì„¤ì •"""
    print("ğŸš€ ì„œë¹„ìŠ¤ ì„¤ì •...")
    
    # í¬íŠ¸ í™•ì¸
    try:
        response = requests.get("http://localhost:8001/health", timeout=5)
        print("âš ï¸ ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
    except requests.exceptions.RequestException:
        print("âœ… í¬íŠ¸ 8001ì´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # ë°©í™”ë²½ ì„¤ì • (í•„ìš”í•œ ê²½ìš°)
    run_command("ufw allow 8001", "ë°©í™”ë²½ í¬íŠ¸ 8001 ì—´ê¸°")

def test_installation():
    """ì„¤ì¹˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì„¤ì¹˜ í…ŒìŠ¤íŠ¸...")
    
    # Python ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° í…ŒìŠ¤íŠ¸
    test_imports = [
        "torch",
        "whisperx", 
        "fastapi",
        "uvicorn",
        "librosa",
        "soundfile",
        "numpy"
    ]
    
    failed_imports = []
    
    for module in test_imports:
        try:
            __import__(module)
            print(f"âœ… {module}: OK")
        except ImportError as e:
            print(f"âŒ {module}: ì‹¤íŒ¨ - {e}")
            failed_imports.append(module)
    
    if failed_imports:
        print(f"âš ï¸ ì‹¤íŒ¨í•œ ëª¨ë“ˆë“¤: {', '.join(failed_imports)}")
        return False
    
    # GPU í…ŒìŠ¤íŠ¸
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
            print(f"âœ… GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        else:
            print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
    except Exception as e:
        print(f"âŒ GPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    return True

def start_server():
    """ì„œë²„ ì‹œì‘"""
    print("ğŸš€ AI Engine ì„œë²„ ì‹œì‘...")
    
    if not os.path.exists("main.py"):
        print("âŒ main.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print("ì„œë²„ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("python main.py")
    print()
    print("ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰:")
    print("nohup python main.py > server.log 2>&1 &")
    
    return True

def main():
    """ë©”ì¸ ì„¤ì • í•¨ìˆ˜"""
    print("ğŸš€ DdalKkak AI Engine RunPod ì„¤ì • ì‹œì‘")
    print("=" * 60)
    
    steps = [
        ("GPU í™˜ê²½ í™•ì¸", check_gpu),
        ("ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜", install_system_dependencies),
        ("Python ì˜ì¡´ì„± ì„¤ì¹˜", install_python_dependencies),
        ("AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ", download_models),
        ("í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±", create_env_file),
        ("ì„œë¹„ìŠ¤ ì„¤ì •", setup_service),
        ("ì„¤ì¹˜ í…ŒìŠ¤íŠ¸", test_installation),
        ("ì„œë²„ ì‹œì‘ ì•ˆë‚´", start_server)
    ]
    
    failed_steps = []
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        try:
            success = step_func()
            if success:
                print(f"âœ… {step_name}: ì™„ë£Œ")
            else:
                print(f"âŒ {step_name}: ì‹¤íŒ¨")
                failed_steps.append(step_name)
        except Exception as e:
            print(f"âŒ {step_name}: ì˜ˆì™¸ ë°œìƒ - {str(e)}")
            failed_steps.append(step_name)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š ì„¤ì • ê²°ê³¼")
    print("="*60)
    
    if failed_steps:
        print("âŒ ì‹¤íŒ¨í•œ ë‹¨ê³„ë“¤:")
        for step in failed_steps:
            print(f"  - {step}")
        print("\nâš ï¸ ì¼ë¶€ ì„¤ì •ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ í•´ê²°í•˜ì„¸ìš”.")
    else:
        print("ğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. .env íŒŒì¼ì—ì„œ HF_TOKEN ì„¤ì •")
        print("2. python main.pyë¡œ ì„œë²„ ì‹œì‘")
        print("3. python test_stt.pyë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")

if __name__ == "__main__":
    if os.geteuid() != 0:
        print("âš ï¸ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” root ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("sudo python runpod_setup.py ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)
    
    main()