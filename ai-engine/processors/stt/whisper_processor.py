"""
WhisperX STT Processor
RunPod GPU í™˜ê²½ì—ì„œ WhisperX ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì²˜ë¦¬
"""

import os
import asyncio
import time
import logging
from typing import Dict, List, Optional, Union, Any
from pathlib import Path
import tempfile
import aiofiles
import torch
import whisperx
import librosa
import soundfile as sf
from concurrent.futures import ThreadPoolExecutor
import gc

logger = logging.getLogger(__name__)

class WhisperXProcessor:
    """
    WhisperXë¥¼ ì‚¬ìš©í•œ STT ì²˜ë¦¬ê¸°
    - íŒŒì¼ ì—…ë¡œë“œ STT
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ STT
    - í™”ì ë¶„ë¦¬ (Diarization)
    - í•œêµ­ì–´ íŠ¹í™” ìµœì í™”
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        self.model = None
        self.align_model = None
        self.diarize_model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.compute_type = "float16" if self.device == "cuda" else "int8"
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        logger.info(f"ğŸ¯ WhisperX Processor ì´ˆê¸°í™” - Device: {self.device}")
    
    def _get_default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            "model_size": "large-v3",  # large-v3 ëª¨ë¸ ì‚¬ìš©
            "language": "ko",          # í•œêµ­ì–´ ê¸°ë³¸
            "batch_size": 16,          # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
            "chunk_length": 30,        # 30ì´ˆ ì²­í¬
            "enable_diarization": True, # í™”ì ë¶„ë¦¬ í™œì„±í™”
            "hf_token": os.getenv("HF_TOKEN"),  # Hugging Face í† í°
            "max_audio_length": 3600,   # ìµœëŒ€ 1ì‹œê°„ ì˜¤ë””ì˜¤
            "sample_rate": 16000,       # ìƒ˜í”Œë§ ë ˆì´íŠ¸
        }
    
    async def initialize(self):
        """ëª¨ë¸ ì´ˆê¸°í™” (ë¹„ë™ê¸°)"""
        try:
            logger.info("ğŸš€ WhisperX ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # ë©”ì¸ Whisper ëª¨ë¸ ë¡œë“œ
            self.model = whisperx.load_model(
                self.config["model_size"],
                device=self.device,
                compute_type=self.compute_type,
                language=self.config["language"]
            )
            
            # í•œêµ­ì–´ ì •ë ¬ ëª¨ë¸ ë¡œë“œ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                self.align_model, self.align_metadata = whisperx.load_align_model(
                    language_code=self.config["language"],
                    device=self.device
                )
                logger.info("âœ… í•œêµ­ì–´ ì •ë ¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ í•œêµ­ì–´ ì •ë ¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (íƒ€ì„ìŠ¤íƒ¬í”„ ì œí•œ): {e}")
                self.align_model = None
            
            # í™”ì ë¶„ë¦¬ ëª¨ë¸ ë¡œë“œ
            if self.config["enable_diarization"]:
                try:
                    self.diarize_model = whisperx.DiarizationPipeline(
                        use_auth_token=self.config["hf_token"],
                        device=self.device
                    )
                    logger.info("âœ… í™”ì ë¶„ë¦¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ í™”ì ë¶„ë¦¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    self.diarize_model = None
            
            logger.info("ğŸ‰ WhisperX ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ WhisperX ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    async def process_audio_file(
        self,
        audio_url: str,
        meeting_id: str,
        language: str = "ko"
    ) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ STT ì²˜ë¦¬
        """
        start_time = time.time()
        temp_file = None
        
        try:
            logger.info(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ STT ì²˜ë¦¬ ì‹œì‘: {meeting_id}")
            
            # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬
            audio_data, temp_file = await self._download_and_preprocess_audio(audio_url)
            
            # 2. WhisperX STT ì²˜ë¦¬ (ë¸”ë¡œí‚¹ ì‘ì—…ì„ executorì—ì„œ ì‹¤í–‰)
            result = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self._process_with_whisperx,
                temp_file,
                language
            )
            
            # 3. ê²°ê³¼ í›„ì²˜ë¦¬
            processed_result = await self._postprocess_result(result, meeting_id)
            
            processing_time = time.time() - start_time
            processed_result["processing_time"] = processing_time
            
            logger.info(f"âœ… STT ì²˜ë¦¬ ì™„ë£Œ: {meeting_id} ({processing_time:.2f}ì´ˆ)")
            return processed_result
            
        except Exception as e:
            logger.error(f"âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨: {meeting_id} - {e}")
            raise
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_file and os.path.exists(temp_file):
                os.unlink(temp_file)
    
    def _process_with_whisperx(self, audio_file: str, language: str) -> Dict:
        """WhisperX ì‹¤ì œ ì²˜ë¦¬ (ë™ê¸° í•¨ìˆ˜)"""
        try:
            # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = whisperx.load_audio(audio_file)
            
            # 2. STT ë³€í™˜
            result = self.model.transcribe(
                audio,
                batch_size=self.config["batch_size"],
                language=language
            )
            
            # 3. ì •ë ¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            if self.align_model:
                result = whisperx.align(
                    result["segments"],
                    self.align_model,
                    self.align_metadata,
                    audio,
                    self.device,
                    return_char_alignments=False
                )
            
            # 4. í™”ì ë¶„ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            if self.diarize_model:
                diarize_segments = self.diarize_model(audio_file)
                result = whisperx.assign_word_speakers(diarize_segments, result)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ WhisperX ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    async def _download_and_preprocess_audio(self, audio_url: str) -> tuple:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_file = tempfile.NamedTemporaryFile(
                delete=False,
                suffix=".wav",
                prefix="ddalkkak_audio_"
            )
            temp_path = temp_file.name
            temp_file.close()
            
            # URLì´ ë¡œì»¬ íŒŒì¼ì¸ì§€ í™•ì¸
            if audio_url.startswith(('http://', 'https://')):
                # HTTP ë‹¤ìš´ë¡œë“œ (ì¶”í›„ êµ¬í˜„)
                raise NotImplementedError("HTTP ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œëŠ” ì¶”í›„ êµ¬í˜„ ì˜ˆì •")
            else:
                # ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬
                if not os.path.exists(audio_url):
                    raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_url}")
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ì„ 16kHz WAVë¡œ ë³€í™˜
                audio_data, sr = librosa.load(
                    audio_url,
                    sr=self.config["sample_rate"],
                    mono=True
                )
                
                # ìµœëŒ€ ê¸¸ì´ í™•ì¸
                if len(audio_data) > self.config["max_audio_length"] * self.config["sample_rate"]:
                    raise ValueError("ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 1ì‹œê°„)")
                
                # WAV íŒŒì¼ë¡œ ì €ì¥
                sf.write(temp_path, audio_data, self.config["sample_rate"])
                
                logger.info(f"ğŸ“ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(audio_data)/sr:.1f}ì´ˆ")
                return audio_data, temp_path
                
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if temp_path and os.path.exists(temp_path):
                os.unlink(temp_path)
            raise
    
    async def _postprocess_result(self, result: Dict, meeting_id: str) -> Dict[str, Any]:
        """STT ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            full_text = " ".join([seg["text"] for seg in result.get("segments", [])])
            
            # í™”ìë³„ ì •ë³´ ì¶”ì¶œ
            speakers = {}
            segments_with_speakers = []
            
            for segment in result.get("segments", []):
                segment_data = {
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment.get("text", ""),
                    "confidence": segment.get("no_speech_prob", 0.0)
                }
                
                # í™”ì ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                if "speaker" in segment:
                    speaker_id = segment["speaker"]
                    segment_data["speaker"] = speaker_id
                    
                    if speaker_id not in speakers:
                        speakers[speaker_id] = {
                            "total_duration": 0,
                            "segments_count": 0,
                            "text_parts": []
                        }
                    
                    duration = segment_data["end"] - segment_data["start"]
                    speakers[speaker_id]["total_duration"] += duration
                    speakers[speaker_id]["segments_count"] += 1
                    speakers[speaker_id]["text_parts"].append(segment_data["text"])
                
                segments_with_speakers.append(segment_data)
            
            # ê²°ê³¼ êµ¬ì„±
            processed_result = {
                "meeting_id": meeting_id,
                "transcript": full_text,
                "segments": segments_with_speakers,
                "speakers": speakers,
                "language": result.get("language", "ko"),
                "total_segments": len(segments_with_speakers),
                "total_speakers": len(speakers),
                "confidence": self._calculate_average_confidence(segments_with_speakers),
                "has_diarization": len(speakers) > 0
            }
            
            return processed_result
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _calculate_average_confidence(self, segments: List[Dict]) -> float:
        """í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
        if not segments:
            return 0.0
        
        confidences = [seg.get("confidence", 0.0) for seg in segments]
        return sum(confidences) / len(confidences)
    
    async def process_audio_stream(
        self,
        audio_chunk: bytes,
        session_id: str
    ) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (ì¶”í›„ êµ¬í˜„)
        """
        # TODO: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ êµ¬í˜„
        logger.info(f"ğŸ¤ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬: {session_id}")
        
        return {
            "session_id": session_id,
            "partial_text": "ì‹¤ì‹œê°„ ì²˜ë¦¬ êµ¬í˜„ ì˜ˆì •",
            "is_final": False,
            "confidence": 0.0
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            logger.info("ğŸ§¹ WhisperX í”„ë¡œì„¸ì„œ ì •ë¦¬ ì¤‘...")
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if self.model:
                del self.model
            if self.align_model:
                del self.align_model
            if self.diarize_model:
                del self.diarize_model
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ThreadPoolExecutor ì¢…ë£Œ
            self.executor.shutdown(wait=True)
            
            logger.info("âœ… WhisperX í”„ë¡œì„¸ì„œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ì „ì—­ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
whisper_processor = None

async def get_whisper_processor() -> WhisperXProcessor:
    """WhisperX í”„ë¡œì„¸ì„œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global whisper_processor
    
    if whisper_processor is None:
        whisper_processor = WhisperXProcessor()
        await whisper_processor.initialize()
    
    return whisper_processor

async def cleanup_whisper_processor():
    """í”„ë¡œì„¸ì„œ ì •ë¦¬"""
    global whisper_processor
    
    if whisper_processor:
        await whisper_processor.cleanup()
        whisper_processor = None